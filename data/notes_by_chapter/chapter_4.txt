This page contains all content from the legacy PDF notes; classification chapter.
As we phase out the PDF, this page may receive updates not reflected in the static PDF.
4.1 Classification
Classification is a machine learning problem seeking to map from inputs 
 to
outputs in an unordered set.
Examples of classification output sets could be 
 if we’re
trying to figure out what type of fruit we have, or 
 if
we’re working in an emergency room and trying to give the best medical care to a
new patient. We focus on an essential simple case, binary classification, where we aim
to find a mapping from 
 to two outputs. While we should think of the outputs as
not having an order, it’s often convenient to encode them as 
. As before, let
the letter  (for hypothesis) represent a classifier, so the classification process looks
like:
Like regression, classification is a supervised learning problem, in which we are given
a training data set of the form
We will assume that each 
 is a 
 column vector. The intended use of this data
is that, when given an input 
, the learned hypothesis should generate output 
.
What makes a classifier useful? As in regression, we want it to work well on new
data, making good predictions on examples it hasn’t seen. But we don’t know
exactly what data this classifier might be tested on when we use it in the real world.
So, we have to assume a connection between the training data and testing data;
typically, they are drawn independently from the same probability distribution.
In classification, we will often use 0-1 loss for evaluation (as discussed in
Section 1.3). For that choice, we can write the training error and the testing error. In
particular, given a training set 
 and a classifier , we define the training error of 
to be
4  Classification
Note
Rd
{apples, oranges, pears}
{heart attack, no heart attack}
Rd
{+1, 0}
h
x →
→y .
h
Dtrain = {(x(1), y(1)), … , (x(n), y(n))} .
x(i)
d × 1
x(i)
y(i)
Dn
h
h
This is in contrast to a continuous
real-valued output, as we saw for
linear regression.
4  Classification

3
 For now, we will try to find a classifier with small training error (later, with some
added criteria) and hope it generalizes well to new data, and has a small test error
on 
 new examples that were not used in the process of finding the classifier.
We begin by introducing the hypothesis class of linear classifiers (Section 4.2) and
then define an optimization framework to learn linear logistic classifiers (Section 4.3).
4.2 Linear classifiers
We start with the hypothesis class of linear classifiers. They are (relatively) easy to
understand, simple in a mathematical sense, powerful on their own, and the basis
for many other more sophisticated methods. Following their definition, we present
a simple learning algorithm for classifiers.
A linear classifier in  dimensions is defined by a vector of parameters 
 and
scalar 
. So, the hypothesis class 
 of linear classifiers in  dimensions is
parameterized by the set of all vectors in 
. We’ll assume that  is a 
column vector.
Given particular values for  and 
, the classifier is defined by
Remember that we can think of 
 as specifying a -dimensional hyperplane
(compare the above with Equation 2.3). But this time, rather than being interested in
that hyperplane’s values at particular points , we will focus on the separator that it
induces. The separator is the set of  values such that 
. This is also a
hyperplane, but in 
 dimensions! We can interpret  as a vector that is
perpendicular to the separator. (We will also say that  is normal to the separator.)
Below is an embedded demo illustrating the separator and normal vector. Open
demo in full screen.
Etrain(h) = 1
n
n
∑
i=1
{
.
1
h(x(i)) ≠y(i)
0
otherwise
(4.1)
Etest(h) = 1
n′
n+n′
∑
i=n+1
{1
h(x(i)) ≠y(i)
0
otherwise
n′
4.2.1 Linear classifiers: definition
d
θ ∈Rd
θ0 ∈R
H
d
Rd+1
θ
d × 1
θ
θ0
h(x; θ, θ0) = step(θTx + θ0) = {
.
+1
if θTx + θ0 > 0
0
otherwise
θ, θ0
d
x
x
θTx + θ0 = 0
d −1
θ
θ
Demo: Linear classifier separator
 θ₁:
0.5
θ₂:
0.5
θ₀:
0.0
Toggle z=0
Surface
Built with ❤️ by Shen² | Report a Bug
Features (x₁, x₂) & z = θ₁x₁ + θ₂x₂ + θ₀
−2
−1
0
1
2
−5
0
5
Separator
Normal vecto
Prediction: P
Prediction: N
Feature space (x₁, x₂
x₁
x₂
 
For example, in two dimensions (
) the separator has dimension 1, which
means it is a line, and the two components of 
 give the orientation of
the separator, as illustrated in the following example.
Let  be the linear classifier defined by 
. The diagram below shows the 
vector (in green) and the separator it defines:
d = 2
θ = [θ1, θ2]T
4.2.2 Linear classifiers: examples
Example:
h
θ = [
], θ0 = 1
1
−1
θ
 θTx + θ0 = 0
x1
x2
θ
θ2
θ1
What is 
? We can solve for it by plugging a point on the line into the equation for the
line. It is often convenient to choose a point on one of the axes, e.g., in this case,
, for which 
, giving 
.
In this example, the separator divides 
, the space our 
 points live in, into two
half-spaces. The one that is on the same side as the normal vector is the positive half-
space, and we classify all points in that space as positive. The half-space on the
other side is negative and all points in it are classified as negative.
Note that we will call a separator a linear separator of a data set if all of the data with
one label falls on one side of the separator and all of the data with the other label
falls on the other side of the separator. For instance, the separator in the next
example is a linear separator for the illustrated data. If there exists a linear separator
on a dataset, we call this dataset linearly separable.
Let  be the linear classifier defined by 
.
The diagram below shows several points classified by . In particular, let 
 and
.
θ0
x = [0, 1]T
θT [ ] + θ0 = 0
0
1
θ0 = 1
Rd
x(i)
Example:
h
θ = [
], θ0 = 3
−1
1.5
h
x(1) = [ ]
3
2
x(2) = [
]
4
−1
(
[ ]
)
 Thus, 
 and 
 are given positive (label +1) and negative (label 0) classifications,
respectively.
❓ Study Question
What is the green vector normal to the separator? Specify it as a column vector.
❓ Study Question
What change would you have to make to 
 if you wanted to have the
separating hyperplane in the same place, but to classify all the points labeled ‘+’
in the diagram as negative and all the points labeled ‘-’ in the diagram as
positive?
4.3 Linear logistic classifiers
Given a data set and the hypothesis class of linear classifiers, our goal will be to find
the linear classifier that optimizes an objective function relating its predictions to
the training data. To make this problem computationally reasonable, we will need
to take care in how we formulate the optimization problem to achieve this goal.
For classification, it is natural to make predictions in 
 and use the 0-1 loss
function, 
, as introduced in Chapter 1:
h(x(1); θ, θ0) = step ([
] [ ] + 3) = step(3) = +1
h(x(2); θ, θ0) = step ([
] [
] + 3) = step(−2.5) = 0
−1
1.5
3
2
−1
1.5
4
−1
x(1)
x(2)
θ, θ0
{+1, 0}
L01
L01(g, a) = {
.
0
if g = a
1
otherwise
 However, even for simple linear classifiers, it is very difficult to find values for 
that minimize simple 0-1 training error
This problem is NP-hard, which probably implies that solving the most difficult
instances of this problem would require computation time exponential in the number
of training examples, .
What makes this a difficult optimization problem is its lack of “smoothness”:
There can be two hypotheses, 
 and 
, where one is closer in
parameter space to the optimal parameter values 
, but they make the
same number of misclassifications so they have the same  value.
All predictions are categorical: the classifier can’t express a degree of certainty
about whether a particular input  should have an associated value .
For these reasons, if we are considering a hypothesis 
 that makes five incorrect
predictions, it is difficult to see how we might change 
 so that it will perform
better, which makes it difficult to design an algorithm that searches in a sensible
way through the space of hypotheses for a good one. For these reasons, we
investigate another hypothesis class: linear logistic classifiers, providing their
definition, then an approach for learning such classifiers using optimization.
The hypotheses in a linear logistic classifier (LLC) are parameterized by a -
dimensional vector  and a scalar 
, just as is the case for linear classifiers.
However, instead of making predictions in 
, LLC hypotheses generate real-
valued outputs in the interval 
. An LLC has the form
This looks familiar! What’s new?
The logistic function, also known as the sigmoid function, is defined as
and is plotted below, as a function of its input . Its output can be interpreted as a
probability, because for any value of  the output is in 
.
θ, θ0
J(θ, θ0) = 1
n
n
∑
i=1
L01(step(θTx(i) + θ0), y(i)) .
n
(θ, θ0)
(θ′, θ′
0)
(θ∗, θ∗
0)
J
x
y
θ, θ0
θ, θ0
4.3.1 Linear logistic classifiers: definition
d
θ
θ0
{+1, 0}
(0, 1)
h(x; θ, θ0) = σ(θTx + θ0) .
σ(z) =
1
1 + e−z
,
z
z
(0, 1)
The “probably” here is not because
we’re too lazy to look it up, but
actually because of a fundamental
unsolved problem in computer-
science theory, known as “P
vs. NP.”
 −4
−2
2
4
0.5
1
z
σ(z)
❓ Study Question
Convince yourself the output of  is always in the interval 
. Why can’t it
equal 0 or equal 1? For what value of  does 
?
What does an LLC look like? Let’s consider the simple case where 
, so our
input points simply lie along the  axis. Classifiers in this case have dimension ,
meaning that they are points. The plot below shows LLCs for three different
parameter settings: 
, 
, and 
−4
−2
2
4
0.5
1
x
σ(θT x + θ0)
❓ Study Question
Which plot is which? What governs the steepness of the curve? What governs
the  value where the output is equal to 0.5?
But wait! Remember that the definition of a classifier is that it’s a mapping from
 or to some other discrete set. So, then, it seems like an LLC is actually
not a classifier!
Given an LLC, with an output value in 
, what should we do if we are forced to
make a prediction in 
? A default answer is to predict 
 if
σ
(0, 1)
z
σ(z) = 0.5
4.3.2 Linear logistic classifier: examples
d = 1
x
0
σ(10x + 1) σ(−2x + 1)
σ(2x −3).
x
Rd →{+1, 0}
(0, 1)
{+1, 0}
+1
  and  otherwise. The value 
 is sometimes called a prediction
threshold.
In fact, for different problem settings, we might prefer to pick a different prediction
threshold. The field of decision theory considers how to make this choice. For
example, if the consequences of predicting 
 when the answer should be 
 are
much worse than the consequences of predicting 
 when the answer should be 
, then we might set the prediction threshold to be greater than 
.
❓ Study Question
Using a prediction threshold of 0.5, for what values of  do each of the LLCs
shown in the figure above predict 
?
When 
, then our inputs  lie in a two-dimensional space with axes 
 and 
,
and the output of the LLC is a surface, as shown below, for 
.
❓ Study Question
Convince yourself that the set of points for which 
, that is, the
``boundary’’ between positive and negative predictions with prediction
threshold 
, is a line in 
 space. What particular line is it for the case in
the figure above? How would the plot change for 
, but now with
? For 
?
Optimization is a key approach to solving machine learning problems; this also
applies to learning linear logistic classifiers (LLCs) by defining an appropriate loss
function for optimization. A first attempt might be to use the simple 0-1 loss
σ(θTx + θ0) > 0.5
0
0.5
+1
−1
−1
+1
0.5
x
+1
d = 2
x
x1
x2
θ = (1, 1), θ0 = 2
σ(θTx + θ0) = 0.5
0.5
(x1, x2)
θ = (1, 1)
θ0 = −2
θ = (−1, −1), θ0 = 2
4.3.3 Learning linear logistic classifiers
 function 
 that gives a value of 0 for a correct prediction, and a 1 for an incorrect
prediction. As noted earlier, however, this gives rise to an objective function that is
very difficult to optimize, and so we pursue another strategy for defining our
objective.
For learning LLCs, we’d have a class of hypotheses whose outputs are in 
, but
for which we have training data with  values in 
. How can we define an
appropriate loss function? We start by changing our interpretation of the output to
be the probability that the input should map to output value 1 (we might also say that
this is the probability that the input is in class 1 or that the input is ‘positive.’)
❓ Study Question
If 
 is the probability that  belongs to class 
, what is the probability that
 belongs to the class 
, assuming there are only these two classes?
Intuitively, we would like to have low loss if we assign a high probability to the correct
class. We’ll define a loss function, called negative log-likelihood (NLL), that does just
this. In addition, it has the cool property that it extends nicely to the case where we
would like to classify our inputs into more than two classes.
In order to simplify the description, we assume that (or transform our data so that)
the labels in the training data are 
.
We would like to pick the parameters of our classifier to maximize the probability
assigned by the LLC to the correct  values, as specified in the training set. Letting
guess 
, that probability is
under the assumption that our predictions are independent. This can be cleverly
rewritten, when 
, as
❓ Study Question
Be sure you can see why these two expressions are the same.
The big product above is kind of hard to deal with in practice, though. So what can
we do? Because the log function is monotonic, the 
 that maximize the quantity
L01
(0, 1)
y
{+1, 0}
h(x)
x
+1
x
−1
y ∈{0, 1}
y
g(i) = σ(θTx(i) + θ0)
n
∏
i=1
{
,
g(i)
if y(i) = 1
1 −g(i)
otherwise
y(i) ∈{0, 1}
n
∏
i=1
g(i)y(i)
(1 −g(i))1−y(i) .
θ, θ0
Remember to be sure your  values
have this form if you try to learn an
LLC using NLL!
y
That crazy huge  represents
taking the product over a bunch of
factors just as huge  represents
taking the sum over a bunch of
terms.
Π
Σ
 above will be the same as the 
 that maximize its log, which is the following:
Finally, we can turn the maximization problem above into a minimization problem
by taking the negative of the above expression, and writing in terms of minimizing
a loss
where 
 is the negative log-likelihood loss function:
This loss function is also sometimes referred to as the log loss or cross entropy. and it
won’t make any real difference. If we ask you for numbers, use log base .
What is the objective function for linear logistic classification? We can finally put
all these pieces together and develop an objective function for optimizing
regularized negative log-likelihood for a linear logistic classifier. In fact, this process
is usually called “logistic regression,” so we’ll call our objective 
, and define it as
❓ Study Question
Consider the case of linearly separable data. What will the  values that
optimize this objective be like if 
? What will they be like if  is very big?
Try to work out an example in one dimension with two data points.
What role does regularization play for classifiers? This objective function has the
same structure as the one we used for regression, Equation 2.2, where the first term
(in parentheses) is the average loss, and the second term is for regularization.
Regularization is needed for building classifiers that can generalize well (just as was
the case for regression). The parameter  governs the trade-off between the two
terms as illustrated in the following example.
Suppose we wish to obtain a linear logistic classifier for this one-dimensional
dataset:
θ, θ0
n
∑
i=1
(y(i) log g(i) + (1 −y(i)) log(1 −g(i))) .
n
∑
i=1
Lnll(g(i), y(i))
Lnll
Lnll(guess, actual) = −(actual ⋅log(guess) + (1 −actual) ⋅log(1 −guess)) .
e
Jlr
Jlr(θ, θ0; D) = ( 1
n
n
∑
i=1
Lnll(σ(θTx(i) + θ0), y(i))) + λ∥θ∥2 .
(4.2)
θ
λ = 0
λ
λ
 Clearly, this can be fit very nicely by a hypothesis 
, but what is the best
value for ? Evidently, when there is no regularization (
), the objective
function 
 will approach zero for large values of , as shown in the plot on the
left, below. However, would the best hypothesis really have an infinite (or very
large) value for ? Such a hypothesis would suggest that the data indicate strong
certainty that a sharp transition between 
 and 
 occurs exactly at 
,
despite the actual data having a wide gap around 
.
In absence of other beliefs about the solution, we might prefer that our linear
logistic classifier not be overly certain about its predictions, and so we might prefer
a smaller  over a large  By not being overconfident, we might expect a somewhat
smaller  to perform better on future examples drawn from this same distribution.
This preference can be realized using a nonzero value of the regularization trade-off
parameter, as illustrated in the plot on the right, above, with 
.
Another nice way of thinking about regularization is that we would like to prevent
our hypothesis from being too dependent on the particular training data that we
were given: we would like for it to be the case that if the training data were changed
slightly, the hypothesis would not change by much.
4.4 Gradient descent for logistic regression
Now that we have a hypothesis class (LLC) and a loss function (NLL), we need to
take some data and find parameters! Sadly, there is no lovely analytical solution like
the one we obtained for regression, in Section 2.7.2. Good thing we studied gradient
h(x) = σ(θx)
θ
λ = 0
Jlr(θ)
θ
θ
y = 0
y = 1
x = 0
x = 0
θ
θ.
θ
λ = 0.2
 descent! We can perform gradient descent on the 
 objective, as we’ll see next. We
can also apply stochastic gradient descent to this problem.
Luckily, 
 has enough nice properties that gradient descent and stochastic
gradient descent should generally “work”. We’ll soon see some more challenging
optimization problems though – in the context of neural networks, in Section 6.7.
First we need derivatives with respect to both 
 (the scalar component) and  (the
vector component) of 
. Explicitly, they are:
Note that 
 will be of shape 
 and 
 will be a scalar since we have
separated 
 from  here.
Putting everything together, our gradient descent algorithm for logistic regression
becomes:
❓ Study Question
Convince yourself that the dimensions of all these quantities are correct, under
the assumption that  is 
.
❓ Study Question
Compute 
 by finding the vector of partial derivatives 
.
What is the shape of 
?
❓ Study Question
Compute 
 by finding the vector of partial derivatives
.
❓ Study Question
Use these last two results to verify our derivation above.
Algorithm 4.1 LR-Gradient-Descent(
)
repeat
Jlr
Jlr
θ0
θ
Θ
∇θJlr(θ, θ0) = 1
n
n
∑
i=1
(g(i) −y(i))x(i) + 2λθ
∂Jlr(θ, θ0)
∂θ0
= 1
n
n
∑
i=1
(g(i) −y(i)) .
∇θJlr
d × 1
∂Jlr
∂θ0
θ0
θ
θ
d × 1
∇θ∥θ∥2
(
∂∥θ∥2
∂θ1 , … ,
∂∥θ∥2
∂θd )
∇θ∥θ∥2
∇θLnll(σ(θTx + θ0), y)
(
∂Lnll(σ(θTx+θ0),y)
∂θ1
, … ,
∂Lnll(σ(θTx+θ0),y)
∂θd
)
θinit, θ0 init, η, ϵ
1: θ(0) ←θinit
2: θ(0)
0
←θ0 init
3: t ←0
4:
 until 
return 
Logistic regression, implemented using batch or stochastic gradient descent, is a
useful and fundamental machine learning technique. We will also see later that it
corresponds to a one-layer neural network with a sigmoidal activation function,
and so is an important step toward understanding neural networks.
Much like the squared-error loss function that we saw for linear regression, the NLL
loss function for linear logistic regression is a convex function of the parameters 
and 
 (below is a proof if you’re interested). This means that running gradient
descent with a reasonable set of hyperparameters will behave nicely.
4.5 Handling multiple classes
So far, we have focused on the binary classification case, with only two possible
classes. But what can we do if we have multiple possible classes (e.g., we want to
predict the genre of a movie)? There are two basic strategies:
Train multiple binary classifiers using different subsets of our data and
combine their outputs to make a class prediction.
Directly train a multi-class classifier using a hypothesis class that is a
generalization of logistic regression, using a one-hot output encoding and NLL
loss.
The method based on NLL is in wider use, especially in the context of neural
networks, and is explored here. In the following, we will assume that we have a
data set 
 in which the inputs 
 but the outputs 
 are drawn from a set of
 classes 
. Next, we extend the idea of NLL directly to multi-class
classification with 
 classes, where the training label is represented with what is
called a one-hot vector 
, where 
 if the example is of class 
and 
 otherwise. Now, we have a problem of mapping an input 
 that is in
 into a 
-dimensional output. Furthermore, we would like this output to be
interpretable as a discrete probability distribution over the possible classes, which
5:
t ←t + 1
6:
θ(t) ←θ(t−1) −η( 1
n ∑n
i=1(σ(θ(t−1)Tx(i) + θ(t−1)
0
) −y(i))x(i) + 2λ θ(t−1))
7:
θ(t)
0 ←θ(t−1)
0
−η( 1
n ∑n
i=1(σ(θ(t−1)Tx(i) + θ(t−1)
0
) −y(i)))
8:
Jlr(θ(t), θ(t)
0 ) −Jlr(θ(t−1), θ(t−1)
0
) < ϵ
∣∣
9:
θ(t), θ(t)
0
4.4.1 Convexity of the NLL Loss Function
θ
θ0
Proof of convexity of the NLL loss function
D
x(i) ∈Rd
y(i)
K
{c1, … , cK}
K
y = [
]T
y1, … , yK
yk = 1
k
yk = 0
x(i)
Rd
K
 means the elements of the output vector have to be non-negative (greater than or
equal to 0) and sum to 1.
We will do this in two steps. First, we will map our input 
 into a vector value
 by letting  be a whole 
 matrix of parameters, and 
 be a 
vector, so that
Next, we have to extend our use of the sigmoid function to the multi-dimensional
softmax function, that takes a whole vector 
 and generates
which can be interpreted as a probability distribution over 
 items. To make the
final prediction of the class label, we can then look at 
 find the most likely
probability over these 
 entries in 
 (i.e. find the largest entry in 
) and return the
corresponding index as the “one-hot” element of  in our prediction.
❓ Study Question
Convince yourself that the vector of  values will be non-negative and sum to 1.
Putting these steps together, our hypotheses will be
Now, we retain the goal of maximizing the probability that our hypothesis assigns
to the correct output 
 for each input . We can write this probability, letting 
stand for our “guess”, 
, for a single example 
 as 
.
❓ Study Question
How many elements that are not equal to 1 will there be in this product?
The negative log of the probability that we are making a correct guess is, then, for
one-hot vector  and probability distribution vector ,
We’ll call this nllm for negative log likelihood multiclass. It is also worth noting that the
NLLM loss function is also convex; however, we will omit the proof.
x(i)
z(i) ∈RK
θ
d × K
θ0
K × 1
z = θTx + θ0 .
z ∈RK
g = softmax(z) =
.
⎡
⎢
⎣
exp(z1)/ ∑i exp(zi)
⋮
exp(zK)/ ∑i exp(zi)
⎤
⎥
⎦
K
g,
K
g,
g,
1
g
h(x; θ, θ0) = softmax(θTx + θ0) .
yk
x
g
h(x)
(x, y)
∏K
k=1 gyk
k
y
g
Lnllm(g, y) = −
K
∑
k=1
yk ⋅log(gk) .
Let’s check dimensions! 
 is
 and  is 
, and 
 is
, so  is 
 and we’re
good!
θT
K × d
x
d × 1
θ0
K × 1
z
K × 1
 ❓ Study Question
Be sure you see that is 
 is minimized when the guess assigns high
probability to the true class.
❓ Study Question
Show that 
 for 
 is the same as 
.
4.6 Prediction accuracy and validation
In order to formulate classification with a smooth objective function that we can
optimize robustly using gradient descent, we changed the output from discrete
classes to probability values and the loss function from 0-1 loss to NLL. However,
when time comes to actually make a prediction we usually have to make a hard
choice: buy stock in Acme or not? And, we get rewarded if we guessed right,
independent of how sure or not we were when we made the guess.
The performance of a classifier is often characterized by its accuracy, which is the
percentage of a data set that it predicts correctly in the case of 0-1 loss. We can see
that accuracy of hypothesis  on data 
 is the fraction of the data set that does not
incur any loss:
where 
 is the final guess for one class or the other that we make from 
,
e.g., after thresholding. It’s noteworthy here that we use a different loss function for
optimization than for evaluation. This is a compromise we make for computational
ease and efficiency.
Lnllm
Lnllm
K = 2
Lnll
h
D
A(h; D) = 1 −1
n
n
∑
i=1
L01(g(i), y(i)) ,
g(i)
h(x(i))