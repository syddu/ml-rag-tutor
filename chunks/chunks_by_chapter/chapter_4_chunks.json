["This page contains all content from the legacy PDF notes; classification chapter.\nAs we phase out the PDF, this page may receive updates not reflected in the static PDF.\n4.1 Classification", "4.1 Classification\nClassification is a machine learning problem seeking to map from inputs \n to\noutputs in an unordered set.\nExamples of classification output sets could be \n if we\u2019re", "if we\u2019re\ntrying to figure out what type of fruit we have, or \n if\nwe\u2019re working in an emergency room and trying to give the best medical care to a", "new patient. We focus on an essential simple case, binary classification, where we aim\nto find a mapping from \n to two outputs. While we should think of the outputs as", "not having an order, it\u2019s often convenient to encode them as \n. As before, let\nthe letter  (for hypothesis) represent a classifier, so the classification process looks\nlike:", "like:\nLike regression, classification is a supervised learning problem, in which we are given\na training data set of the form\nWe will assume that each \n is a", "is a \n column vector. The intended use of this data\nis that, when given an input \n, the learned hypothesis should generate output \n.", ".\nWhat makes a classifier useful? As in regression, we want it to work well on new\ndata, making good predictions on examples it hasn\u2019t seen. But we don\u2019t know", "exactly what data this classifier might be tested on when we use it in the real world.\nSo, we have to assume a connection between the training data and testing data;", "typically, they are drawn independently from the same probability distribution.\nIn classification, we will often use 0-1 loss for evaluation (as discussed in", "Section 1.3). For that choice, we can write the training error and the testing error. In\nparticular, given a training set \n and a classifier , we define the training error of \nto be\n4  Classification", "4  Classification\nNote\nRd\n{apples, oranges, pears}\n{heart attack, no heart attack}\nRd\n{+1, 0}\nh\nx \u2192\n\u2192y .\nh\nDtrain = {(x(1), y(1)), \u2026 , (x(n), y(n))} .\nx(i)\nd \u00d7 1\nx(i)\ny(i)\nDn\nh\nh", "x(i)\ny(i)\nDn\nh\nh\nThis is in contrast to a continuous\nreal-valued output, as we saw for\nlinear regression.\n\uf4614  Classification\n\uf52a\n3", "\uf52a\n3\n For now, we will try to find a classifier with small training error (later, with some\nadded criteria) and hope it generalizes well to new data, and has a small test error\non", "on \n new examples that were not used in the process of finding the classifier.\nWe begin by introducing the hypothesis class of linear classifiers (Section 4.2) and", "then define an optimization framework to learn linear logistic classifiers (Section 4.3).\n4.2 Linear classifiers", "We start with the hypothesis class of linear classifiers. They are (relatively) easy to\nunderstand, simple in a mathematical sense, powerful on their own, and the basis", "for many other more sophisticated methods. Following their definition, we present\na simple learning algorithm for classifiers.\nA linear classifier in  dimensions is defined by a vector of parameters", "and\nscalar \n. So, the hypothesis class \n of linear classifiers in  dimensions is\nparameterized by the set of all vectors in \n. We\u2019ll assume that  is a \ncolumn vector.", "column vector.\nGiven particular values for  and \n, the classifier is defined by\nRemember that we can think of \n as specifying a -dimensional hyperplane", "(compare the above with Equation 2.3). But this time, rather than being interested in\nthat hyperplane\u2019s values at particular points , we will focus on the separator that it", "induces. The separator is the set of  values such that \n. This is also a\nhyperplane, but in \n dimensions! We can interpret  as a vector that is", "perpendicular to the separator. (We will also say that  is normal to the separator.)\nBelow is an embedded demo illustrating the separator and normal vector. Open\ndemo in full screen.\nEtrain(h) = 1\nn", "Etrain(h) = 1\nn\nn\n\u2211\ni=1\n{\n.\n1\nh(x(i)) \u2260y(i)\n0\notherwise\n(4.1)\nEtest(h) = 1\nn\u2032\nn+n\u2032\n\u2211\ni=n+1\n{1\nh(x(i)) \u2260y(i)\n0\notherwise\nn\u2032\n4.2.1 Linear classifiers: definition\nd\n\u03b8 \u2208Rd\n\u03b80 \u2208R\nH\nd\nRd+1\n\u03b8\nd \u00d7 1\n\u03b8\n\u03b80", "d\nRd+1\n\u03b8\nd \u00d7 1\n\u03b8\n\u03b80\nh(x; \u03b8, \u03b80) = step(\u03b8Tx + \u03b80) = {\n.\n+1\nif \u03b8Tx + \u03b80 > 0\n0\notherwise\n\u03b8, \u03b80\nd\nx\nx\n\u03b8Tx + \u03b80 = 0\nd \u22121\n\u03b8\n\u03b8\nDemo: Linear classifier separator\n \u03b8\u2081:\n0.5\n\u03b8\u2082:\n0.5\n\u03b8\u2080:\n0.0\nToggle z=0\nSurface", "Toggle z=0\nSurface\nBuilt with \u2764\ufe0f by Shen\u00b2 | Report a Bug\nFeatures (x\u2081, x\u2082) & z = \u03b8\u2081x\u2081 + \u03b8\u2082x\u2082 + \u03b8\u2080\n\u22122\n\u22121\n0\n1\n2\n\u22125\n0\n5\nSeparator\nNormal vecto\nPrediction: P\nPrediction: N\nFeature space (x\u2081, x\u2082\nx\u2081\nx\u2082", "x\u2081\nx\u2082\n \nFor example, in two dimensions (\n) the separator has dimension 1, which\nmeans it is a line, and the two components of \n give the orientation of", "the separator, as illustrated in the following example.\nLet  be the linear classifier defined by \n. The diagram below shows the \nvector (in green) and the separator it defines:\nd = 2\n\u03b8 = [\u03b81, \u03b82]T", "d = 2\n\u03b8 = [\u03b81, \u03b82]T\n4.2.2 Linear classifiers: examples\nExample:\nh\n\u03b8 = [\n], \u03b80 = 1\n1\n\u22121\n\u03b8\n \u03b8Tx + \u03b80 = 0\nx1\nx2\n\u03b8\n\u03b82\n\u03b81\nWhat is", "x2\n\u03b8\n\u03b82\n\u03b81\nWhat is \n? We can solve for it by plugging a point on the line into the equation for the\nline. It is often convenient to choose a point on one of the axes, e.g., in this case,\n, for which", ", for which \n, giving \n.\nIn this example, the separator divides \n, the space our \n points live in, into two\nhalf-spaces. The one that is on the same side as the normal vector is the positive half-", "space, and we classify all points in that space as positive. The half-space on the\nother side is negative and all points in it are classified as negative.", "Note that we will call a separator a linear separator of a data set if all of the data with\none label falls on one side of the separator and all of the data with the other label", "falls on the other side of the separator. For instance, the separator in the next\nexample is a linear separator for the illustrated data. If there exists a linear separator", "on a dataset, we call this dataset linearly separable.\nLet  be the linear classifier defined by \n.\nThe diagram below shows several points classified by . In particular, let \n and\n.\n\u03b80\nx = [0, 1]T", ".\n\u03b80\nx = [0, 1]T\n\u03b8T [ ] + \u03b80 = 0\n0\n1\n\u03b80 = 1\nRd\nx(i)\nExample:\nh\n\u03b8 = [\n], \u03b80 = 3\n\u22121\n1.5\nh\nx(1) = [ ]\n3\n2\nx(2) = [\n]\n4\n\u22121\n(\n[ ]\n)\n Thus, \n and", "[ ]\n)\n Thus, \n and \n are given positive (label +1) and negative (label 0) classifications,\nrespectively.\n\u2753 Study Question", "\u2753 Study Question\nWhat is the green vector normal to the separator? Specify it as a column vector.\n\u2753 Study Question\nWhat change would you have to make to \n if you wanted to have the", "separating hyperplane in the same place, but to classify all the points labeled \u2018+\u2019\nin the diagram as negative and all the points labeled \u2018-\u2019 in the diagram as\npositive?", "positive?\n4.3 Linear logistic classifiers\nGiven a data set and the hypothesis class of linear classifiers, our goal will be to find", "the linear classifier that optimizes an objective function relating its predictions to\nthe training data. To make this problem computationally reasonable, we will need", "to take care in how we formulate the optimization problem to achieve this goal.\nFor classification, it is natural to make predictions in \n and use the 0-1 loss\nfunction,", "function, \n, as introduced in Chapter 1:\nh(x(1); \u03b8, \u03b80) = step ([\n] [ ] + 3) = step(3) = +1\nh(x(2); \u03b8, \u03b80) = step ([\n] [\n] + 3) = step(\u22122.5) = 0\n\u22121\n1.5\n3\n2\n\u22121\n1.5\n4\n\u22121\nx(1)\nx(2)\n\u03b8, \u03b80\n{+1, 0}\nL01", "\u03b8, \u03b80\n{+1, 0}\nL01\nL01(g, a) = {\n.\n0\nif g = a\n1\notherwise\n However, even for simple linear classifiers, it is very difficult to find values for \nthat minimize simple 0-1 training error", "This problem is NP-hard, which probably implies that solving the most difficult\ninstances of this problem would require computation time exponential in the number\nof training examples, .", "What makes this a difficult optimization problem is its lack of \u201csmoothness\u201d:\nThere can be two hypotheses, \n and \n, where one is closer in\nparameter space to the optimal parameter values", ", but they make the\nsame number of misclassifications so they have the same  value.\nAll predictions are categorical: the classifier can\u2019t express a degree of certainty", "about whether a particular input  should have an associated value .\nFor these reasons, if we are considering a hypothesis \n that makes five incorrect", "predictions, it is difficult to see how we might change \n so that it will perform\nbetter, which makes it difficult to design an algorithm that searches in a sensible", "way through the space of hypotheses for a good one. For these reasons, we\ninvestigate another hypothesis class: linear logistic classifiers, providing their", "definition, then an approach for learning such classifiers using optimization.\nThe hypotheses in a linear logistic classifier (LLC) are parameterized by a -\ndimensional vector  and a scalar", ", just as is the case for linear classifiers.\nHowever, instead of making predictions in \n, LLC hypotheses generate real-\nvalued outputs in the interval \n. An LLC has the form", "This looks familiar! What\u2019s new?\nThe logistic function, also known as the sigmoid function, is defined as\nand is plotted below, as a function of its input . Its output can be interpreted as a", "probability, because for any value of  the output is in \n.\n\u03b8, \u03b80\nJ(\u03b8, \u03b80) = 1\nn\nn\n\u2211\ni=1\nL01(step(\u03b8Tx(i) + \u03b80), y(i)) .\nn\n(\u03b8, \u03b80)\n(\u03b8\u2032, \u03b8\u2032\n0)\n(\u03b8\u2217, \u03b8\u2217\n0)\nJ\nx\ny\n\u03b8, \u03b80\n\u03b8, \u03b80", "J\nx\ny\n\u03b8, \u03b80\n\u03b8, \u03b80\n4.3.1 Linear logistic classifiers: definition\nd\n\u03b8\n\u03b80\n{+1, 0}\n(0, 1)\nh(x; \u03b8, \u03b80) = \u03c3(\u03b8Tx + \u03b80) .\n\u03c3(z) =\n1\n1 + e\u2212z\n,\nz\nz\n(0, 1)\nThe \u201cprobably\u201d here is not because", "we\u2019re too lazy to look it up, but\nactually because of a fundamental\nunsolved problem in computer-\nscience theory, known as \u201cP\nvs. NP.\u201d\n \u22124\n\u22122\n2\n4\n0.5\n1\nz\n\u03c3(z)\n\u2753 Study Question", "\u2753 Study Question\nConvince yourself the output of  is always in the interval \n. Why can\u2019t it\nequal 0 or equal 1? For what value of  does \n?", "?\nWhat does an LLC look like? Let\u2019s consider the simple case where \n, so our\ninput points simply lie along the  axis. Classifiers in this case have dimension ,", "meaning that they are points. The plot below shows LLCs for three different\nparameter settings: \n, \n, and \n\u22124\n\u22122\n2\n4\n0.5\n1\nx\n\u03c3(\u03b8T x + \u03b80)\n\u2753 Study Question", "\u2753 Study Question\nWhich plot is which? What governs the steepness of the curve? What governs\nthe  value where the output is equal to 0.5?", "But wait! Remember that the definition of a classifier is that it\u2019s a mapping from\n or to some other discrete set. So, then, it seems like an LLC is actually\nnot a classifier!", "not a classifier!\nGiven an LLC, with an output value in \n, what should we do if we are forced to\nmake a prediction in \n? A default answer is to predict \n if\n\u03c3\n(0, 1)\nz\n\u03c3(z) = 0.5", "(0, 1)\nz\n\u03c3(z) = 0.5\n4.3.2 Linear logistic classifier: examples\nd = 1\nx\n0\n\u03c3(10x + 1) \u03c3(\u22122x + 1)\n\u03c3(2x \u22123).\nx\nRd \u2192{+1, 0}\n(0, 1)\n{+1, 0}\n+1\n  and  otherwise. The value \n is sometimes called a prediction", "threshold.\nIn fact, for different problem settings, we might prefer to pick a different prediction\nthreshold. The field of decision theory considers how to make this choice. For", "example, if the consequences of predicting \n when the answer should be \n are\nmuch worse than the consequences of predicting \n when the answer should be", ", then we might set the prediction threshold to be greater than \n.\n\u2753 Study Question\nUsing a prediction threshold of 0.5, for what values of  do each of the LLCs\nshown in the figure above predict \n?", "?\nWhen \n, then our inputs  lie in a two-dimensional space with axes \n and \n,\nand the output of the LLC is a surface, as shown below, for \n.\n\u2753 Study Question", ".\n\u2753 Study Question\nConvince yourself that the set of points for which \n, that is, the\n``boundary\u2019\u2019 between positive and negative predictions with prediction\nthreshold \n, is a line in", ", is a line in \n space. What particular line is it for the case in\nthe figure above? How would the plot change for \n, but now with\n? For \n?", "? For \n?\nOptimization is a key approach to solving machine learning problems; this also\napplies to learning linear logistic classifiers (LLCs) by defining an appropriate loss", "function for optimization. A first attempt might be to use the simple 0-1 loss\n\u03c3(\u03b8Tx + \u03b80) > 0.5\n0\n0.5\n+1\n\u22121\n\u22121\n+1\n0.5\nx\n+1\nd = 2\nx\nx1\nx2\n\u03b8 = (1, 1), \u03b80 = 2\n\u03c3(\u03b8Tx + \u03b80) = 0.5\n0.5\n(x1, x2)\n\u03b8 = (1, 1)", "(x1, x2)\n\u03b8 = (1, 1)\n\u03b80 = \u22122\n\u03b8 = (\u22121, \u22121), \u03b80 = 2\n4.3.3 Learning linear logistic classifiers\n function \n that gives a value of 0 for a correct prediction, and a 1 for an incorrect", "prediction. As noted earlier, however, this gives rise to an objective function that is\nvery difficult to optimize, and so we pursue another strategy for defining our\nobjective.", "objective.\nFor learning LLCs, we\u2019d have a class of hypotheses whose outputs are in \n, but\nfor which we have training data with  values in \n. How can we define an", "appropriate loss function? We start by changing our interpretation of the output to\nbe the probability that the input should map to output value 1 (we might also say that", "this is the probability that the input is in class 1 or that the input is \u2018positive.\u2019)\n\u2753 Study Question\nIf \n is the probability that  belongs to class \n, what is the probability that", "belongs to the class \n, assuming there are only these two classes?\nIntuitively, we would like to have low loss if we assign a high probability to the correct", "class. We\u2019ll define a loss function, called negative log-likelihood (NLL), that does just\nthis. In addition, it has the cool property that it extends nicely to the case where we", "would like to classify our inputs into more than two classes.\nIn order to simplify the description, we assume that (or transform our data so that)\nthe labels in the training data are \n.", ".\nWe would like to pick the parameters of our classifier to maximize the probability\nassigned by the LLC to the correct  values, as specified in the training set. Letting\nguess \n, that probability is", "under the assumption that our predictions are independent. This can be cleverly\nrewritten, when \n, as\n\u2753 Study Question\nBe sure you can see why these two expressions are the same.", "The big product above is kind of hard to deal with in practice, though. So what can\nwe do? Because the log function is monotonic, the \n that maximize the quantity\nL01\n(0, 1)\ny\n{+1, 0}\nh(x)\nx\n+1\nx\n\u22121", "h(x)\nx\n+1\nx\n\u22121\ny \u2208{0, 1}\ny\ng(i) = \u03c3(\u03b8Tx(i) + \u03b80)\nn\n\u220f\ni=1\n{\n,\ng(i)\nif y(i) = 1\n1 \u2212g(i)\notherwise\ny(i) \u2208{0, 1}\nn\n\u220f\ni=1\ng(i)y(i)\n(1 \u2212g(i))1\u2212y(i) .\n\u03b8, \u03b80\nRemember to be sure your  values", "have this form if you try to learn an\nLLC using NLL!\ny\nThat crazy huge  represents\ntaking the product over a bunch of\nfactors just as huge  represents\ntaking the sum over a bunch of\nterms.\n\u03a0\n\u03a3", "terms.\n\u03a0\n\u03a3\n above will be the same as the \n that maximize its log, which is the following:\nFinally, we can turn the maximization problem above into a minimization problem", "by taking the negative of the above expression, and writing in terms of minimizing\na loss\nwhere \n is the negative log-likelihood loss function:", "This loss function is also sometimes referred to as the log loss or cross entropy. and it\nwon\u2019t make any real difference. If we ask you for numbers, use log base .", "What is the objective function for linear logistic classification? We can finally put\nall these pieces together and develop an objective function for optimizing", "regularized negative log-likelihood for a linear logistic classifier. In fact, this process\nis usually called \u201clogistic regression,\u201d so we\u2019ll call our objective \n, and define it as\n\u2753 Study Question", "\u2753 Study Question\nConsider the case of linearly separable data. What will the  values that\noptimize this objective be like if \n? What will they be like if  is very big?", "Try to work out an example in one dimension with two data points.\nWhat role does regularization play for classifiers? This objective function has the", "same structure as the one we used for regression, Equation 2.2, where the first term\n(in parentheses) is the average loss, and the second term is for regularization.", "Regularization is needed for building classifiers that can generalize well (just as was\nthe case for regression). The parameter  governs the trade-off between the two", "terms as illustrated in the following example.\nSuppose we wish to obtain a linear logistic classifier for this one-dimensional\ndataset:\n\u03b8, \u03b80\nn\n\u2211\ni=1\n(y(i) log g(i) + (1 \u2212y(i)) log(1 \u2212g(i))) .\nn\n\u2211", "n\n\u2211\ni=1\nLnll(g(i), y(i))\nLnll\nLnll(guess, actual) = \u2212(actual \u22c5log(guess) + (1 \u2212actual) \u22c5log(1 \u2212guess)) .\ne\nJlr\nJlr(\u03b8, \u03b80; D) = ( 1\nn\nn\n\u2211\ni=1\nLnll(\u03c3(\u03b8Tx(i) + \u03b80), y(i))) + \u03bb\u2225\u03b8\u22252 .\n(4.2)\n\u03b8\n\u03bb = 0\n\u03bb\n\u03bb", "(4.2)\n\u03b8\n\u03bb = 0\n\u03bb\n\u03bb\n Clearly, this can be fit very nicely by a hypothesis \n, but what is the best\nvalue for ? Evidently, when there is no regularization (\n), the objective\nfunction", "function \n will approach zero for large values of , as shown in the plot on the\nleft, below. However, would the best hypothesis really have an infinite (or very", "large) value for ? Such a hypothesis would suggest that the data indicate strong\ncertainty that a sharp transition between \n and \n occurs exactly at \n,", ",\ndespite the actual data having a wide gap around \n.\nIn absence of other beliefs about the solution, we might prefer that our linear", "logistic classifier not be overly certain about its predictions, and so we might prefer\na smaller  over a large  By not being overconfident, we might expect a somewhat", "smaller  to perform better on future examples drawn from this same distribution.\nThis preference can be realized using a nonzero value of the regularization trade-off", "parameter, as illustrated in the plot on the right, above, with \n.\nAnother nice way of thinking about regularization is that we would like to prevent", "our hypothesis from being too dependent on the particular training data that we\nwere given: we would like for it to be the case that if the training data were changed", "slightly, the hypothesis would not change by much.\n4.4 Gradient descent for logistic regression\nNow that we have a hypothesis class (LLC) and a loss function (NLL), we need to", "take some data and find parameters! Sadly, there is no lovely analytical solution like\nthe one we obtained for regression, in Section 2.7.2. Good thing we studied gradient\nh(x) = \u03c3(\u03b8x)\n\u03b8\n\u03bb = 0\nJlr(\u03b8)", "\u03b8\n\u03bb = 0\nJlr(\u03b8)\n\u03b8\n\u03b8\ny = 0\ny = 1\nx = 0\nx = 0\n\u03b8\n\u03b8.\n\u03b8\n\u03bb = 0.2\n descent! We can perform gradient descent on the \n objective, as we\u2019ll see next. We", "can also apply stochastic gradient descent to this problem.\nLuckily, \n has enough nice properties that gradient descent and stochastic", "gradient descent should generally \u201cwork\u201d. We\u2019ll soon see some more challenging\noptimization problems though \u2013 in the context of neural networks, in Section 6.7.", "First we need derivatives with respect to both \n (the scalar component) and  (the\nvector component) of \n. Explicitly, they are:\nNote that \n will be of shape \n and \n will be a scalar since we have", "separated \n from  here.\nPutting everything together, our gradient descent algorithm for logistic regression\nbecomes:\n\u2753 Study Question", "\u2753 Study Question\nConvince yourself that the dimensions of all these quantities are correct, under\nthe assumption that  is \n.\n\u2753 Study Question\nCompute \n by finding the vector of partial derivatives \n.", ".\nWhat is the shape of \n?\n\u2753 Study Question\nCompute \n by finding the vector of partial derivatives\n.\n\u2753 Study Question\nUse these last two results to verify our derivation above.", "Algorithm 4.1 LR-Gradient-Descent(\n)\nrepeat\nJlr\nJlr\n\u03b80\n\u03b8\n\u0398\n\u2207\u03b8Jlr(\u03b8, \u03b80) = 1\nn\nn\n\u2211\ni=1\n(g(i) \u2212y(i))x(i) + 2\u03bb\u03b8\n\u2202Jlr(\u03b8, \u03b80)\n\u2202\u03b80\n= 1\nn\nn\n\u2211\ni=1\n(g(i) \u2212y(i)) .\n\u2207\u03b8Jlr\nd \u00d7 1\n\u2202Jlr\n\u2202\u03b80\n\u03b80\n\u03b8\n\u03b8\nd \u00d7 1\n\u2207\u03b8\u2225\u03b8\u22252\n(", "\u03b8\n\u03b8\nd \u00d7 1\n\u2207\u03b8\u2225\u03b8\u22252\n(\n\u2202\u2225\u03b8\u22252\n\u2202\u03b81 , \u2026 ,\n\u2202\u2225\u03b8\u22252\n\u2202\u03b8d )\n\u2207\u03b8\u2225\u03b8\u22252\n\u2207\u03b8Lnll(\u03c3(\u03b8Tx + \u03b80), y)\n(\n\u2202Lnll(\u03c3(\u03b8Tx+\u03b80),y)\n\u2202\u03b81\n, \u2026 ,\n\u2202Lnll(\u03c3(\u03b8Tx+\u03b80),y)\n\u2202\u03b8d\n)\n\u03b8init, \u03b80 init, \u03b7, \u03f5\n1: \u03b8(0) \u2190\u03b8init\n2: \u03b8(0)\n0\n\u2190\u03b80 init\n3: t \u21900\n4:", "\u2190\u03b80 init\n3: t \u21900\n4:\n until \nreturn \nLogistic regression, implemented using batch or stochastic gradient descent, is a\nuseful and fundamental machine learning technique. We will also see later that it", "corresponds to a one-layer neural network with a sigmoidal activation function,\nand so is an important step toward understanding neural networks.", "Much like the squared-error loss function that we saw for linear regression, the NLL\nloss function for linear logistic regression is a convex function of the parameters \nand", "and \n (below is a proof if you\u2019re interested). This means that running gradient\ndescent with a reasonable set of hyperparameters will behave nicely.\n4.5 Handling multiple classes", "So far, we have focused on the binary classification case, with only two possible\nclasses. But what can we do if we have multiple possible classes (e.g., we want to", "predict the genre of a movie)? There are two basic strategies:\nTrain multiple binary classifiers using different subsets of our data and\ncombine their outputs to make a class prediction.", "Directly train a multi-class classifier using a hypothesis class that is a\ngeneralization of logistic regression, using a one-hot output encoding and NLL\nloss.", "loss.\nThe method based on NLL is in wider use, especially in the context of neural\nnetworks, and is explored here. In the following, we will assume that we have a\ndata set \n in which the inputs", "but the outputs \n are drawn from a set of\n classes \n. Next, we extend the idea of NLL directly to multi-class\nclassification with \n classes, where the training label is represented with what is", "called a one-hot vector \n, where \n if the example is of class \nand \n otherwise. Now, we have a problem of mapping an input \n that is in\n into a", "into a \n-dimensional output. Furthermore, we would like this output to be\ninterpretable as a discrete probability distribution over the possible classes, which\n5:\nt \u2190t + 1\n6:\n\u03b8(t) \u2190\u03b8(t\u22121) \u2212\u03b7( 1\nn \u2211n", "n \u2211n\ni=1(\u03c3(\u03b8(t\u22121)Tx(i) + \u03b8(t\u22121)\n0\n) \u2212y(i))x(i) + 2\u03bb \u03b8(t\u22121))\n7:\n\u03b8(t)\n0 \u2190\u03b8(t\u22121)\n0\n\u2212\u03b7( 1\nn \u2211n\ni=1(\u03c3(\u03b8(t\u22121)Tx(i) + \u03b8(t\u22121)\n0\n) \u2212y(i)))\n8:\nJlr(\u03b8(t), \u03b8(t)\n0 ) \u2212Jlr(\u03b8(t\u22121), \u03b8(t\u22121)\n0\n) < \u03f5\n\u2223\u2223\n9:\n\u03b8(t), \u03b8(t)\n0", "\u2223\u2223\n9:\n\u03b8(t), \u03b8(t)\n0\n4.4.1 Convexity of the NLL Loss Function\n\u03b8\n\u03b80\nProof of convexity of the NLL loss function\nD\nx(i) \u2208Rd\ny(i)\nK\n{c1, \u2026 , cK}\nK\ny = [\n]T\ny1, \u2026 , yK\nyk = 1\nk\nyk = 0\nx(i)\nRd\nK", "k\nyk = 0\nx(i)\nRd\nK\n means the elements of the output vector have to be non-negative (greater than or\nequal to 0) and sum to 1.\nWe will do this in two steps. First, we will map our input", "into a vector value\n by letting  be a whole \n matrix of parameters, and \n be a \nvector, so that\nNext, we have to extend our use of the sigmoid function to the multi-dimensional", "softmax function, that takes a whole vector \n and generates\nwhich can be interpreted as a probability distribution over \n items. To make the\nfinal prediction of the class label, we can then look at", "find the most likely\nprobability over these \n entries in \n (i.e. find the largest entry in \n) and return the\ncorresponding index as the \u201cone-hot\u201d element of  in our prediction.\n\u2753 Study Question", "\u2753 Study Question\nConvince yourself that the vector of  values will be non-negative and sum to 1.\nPutting these steps together, our hypotheses will be", "Now, we retain the goal of maximizing the probability that our hypothesis assigns\nto the correct output \n for each input . We can write this probability, letting \nstand for our \u201cguess\u201d,", ", for a single example \n as \n.\n\u2753 Study Question\nHow many elements that are not equal to 1 will there be in this product?", "The negative log of the probability that we are making a correct guess is, then, for\none-hot vector  and probability distribution vector ,", "We\u2019ll call this nllm for negative log likelihood multiclass. It is also worth noting that the\nNLLM loss function is also convex; however, we will omit the proof.\nx(i)\nz(i) \u2208RK\n\u03b8\nd \u00d7 K\n\u03b80\nK \u00d7 1", "\u03b8\nd \u00d7 K\n\u03b80\nK \u00d7 1\nz = \u03b8Tx + \u03b80 .\nz \u2208RK\ng = softmax(z) =\n.\n\u23a1\n\u23a2\n\u23a3\nexp(z1)/ \u2211i exp(zi)\n\u22ee\nexp(zK)/ \u2211i exp(zi)\n\u23a4\n\u23a5\n\u23a6\nK\ng,\nK\ng,\ng,\n1\ng\nh(x; \u03b8, \u03b80) = softmax(\u03b8Tx + \u03b80) .\nyk\nx\ng\nh(x)\n(x, y)\n\u220fK\nk=1 gyk\nk\ny\ng", "\u220fK\nk=1 gyk\nk\ny\ng\nLnllm(g, y) = \u2212\nK\n\u2211\nk=1\nyk \u22c5log(gk) .\nLet\u2019s check dimensions! \n is\n and  is \n, and \n is\n, so  is \n and we\u2019re\ngood!\n\u03b8T\nK \u00d7 d\nx\nd \u00d7 1\n\u03b80\nK \u00d7 1\nz\nK \u00d7 1\n \u2753 Study Question", "\u2753 Study Question\nBe sure you see that is \n is minimized when the guess assigns high\nprobability to the true class.\n\u2753 Study Question\nShow that \n for \n is the same as \n.", "is the same as \n.\n4.6 Prediction accuracy and validation\nIn order to formulate classification with a smooth objective function that we can", "optimize robustly using gradient descent, we changed the output from discrete\nclasses to probability values and the loss function from 0-1 loss to NLL. However,", "when time comes to actually make a prediction we usually have to make a hard\nchoice: buy stock in Acme or not? And, we get rewarded if we guessed right,", "independent of how sure or not we were when we made the guess.\nThe performance of a classifier is often characterized by its accuracy, which is the", "percentage of a data set that it predicts correctly in the case of 0-1 loss. We can see\nthat accuracy of hypothesis  on data \n is the fraction of the data set that does not\nincur any loss:\nwhere", "where \n is the final guess for one class or the other that we make from \n,\ne.g., after thresholding. It\u2019s noteworthy here that we use a different loss function for", "optimization than for evaluation. This is a compromise we make for computational\nease and efficiency.\nLnllm\nLnllm\nK = 2\nLnll\nh\nD\nA(h; D) = 1 \u22121\nn\nn\n\u2211\ni=1\nL01(g(i), y(i)) ,\ng(i)\nh(x(i))"]