["B.1 Strategies towards adaptive step-size\nWe\u2019ll start by looking at the notion of a running average. It\u2019s a computational", "strategy for estimating a possibly weighted average of a sequence of data. Let our\ndata sequence be \n; then we define a sequence of running average values,\n using the equations\nwhere \n. If", "where \n. If \n is a constant, then this is a moving average, in which\nSo, you can see that inputs \n closer to the end of the sequence have more effect on\n than early inputs.\nIf, instead, we set", ", then we get the actual average.\n\u2753 Study Question\nProve to yourself that the previous assertion holds.\nNow, we can use methods that are a bit like running averages to describe strategies", "for computing . The simplest method is momentum, in which we try to \u201caverage\u201d\nrecent gradient updates, so that if they have been bouncing back and forth in some", "direction, we take out that component of the motion. For momentum, we have\nAppendix B \u2014 Optimizing Neural\nNetworks\nB.1.1 Running averages\nc1, c2, \u2026\nC0, C1, C2, \u2026\nC0 = 0,\nCt = \u03b3t Ct\u22121 + (1 \u2212\u03b3t) ct,", "\u03b3t \u2208(0, 1)\n\u03b3t\nCT = \u03b3 CT\u22121 + (1 \u2212\u03b3) cT\n= \u03b3(\u03b3 CT\u22122 + (1 \u2212\u03b3) cT\u22121) + (1 \u2212\u03b3) cT\n=\nT\n\u2211\nt=1\n\u03b3 T\u2212t(1 \u2212\u03b3) ct.\nct\nCT\n\u03b3t = t\u22121\nt\nB.1.2 Momentum\n\u03b7\nV0 = 0,\nVt = \u03b3 Vt\u22121 + \u03b7 \u2207WJ(Wt\u22121),\nWt = Wt\u22121 \u2212Vt.", "Wt = Wt\u22121 \u2212Vt.\n\uf461Appendices > B  Optimizing Neural Networks\n\uf52a\n This doesn\u2019t quite look like an adaptive step size. But what we can see is that, if we\nlet", "let \n, then the rule looks exactly like doing an update with step size \non a moving average of the gradients with parameter :\n\u2753 Study Question", "\u2753 Study Question\nProve to yourself that these formulations are equivalent.\nWe will find that \n will be bigger in dimensions that consistently have the same\nsign for", "sign for \n and smaller for those that don\u2019t. Of course we now have two\nparameters to set (  and ), but the hope is that the algorithm will perform better", "overall, so it will be worth trying to find good values for them. Often  is set to be\nsomething like \n.\nThe red arrows show the update after each successive step of mini-batch gradient", "descent with momentum. The blue points show the direction of the gradient with\nrespect to the mini-batch at each step. Momentum smooths the path taken towards", "the local minimum and leads to faster convergence.\n\u2753 Study Question\nIf you set \n, would momentum have more of an effect or less of an effect\nthan if you set it to \n?", "?\nAnother useful idea is this: we would like to take larger steps in parts of the space\nwhere \n is nearly flat (because there\u2019s no risk of taking too big a step due to the", "gradient being large) and smaller steps when it is steep. We\u2019ll apply this idea to\neach weight independently, and end up with a method called adadelta, which is a\n\u03b7 = \u03b7\u2032(1 \u2212\u03b3)\n\u03b7\u2032\n\u03b3\nM0 = 0,", "\u03b7\u2032\n\u03b3\nM0 = 0,\nMt = \u03b3 Mt\u22121 + (1 \u2212\u03b3) \u2207WJ(Wt\u22121),\nWt = Wt\u22121 \u2212\u03b7\u2032 Mt.\nVt\n\u2207W\n\u03b7\n\u03b3\n\u03b3\n0.9\n\u03b3 = 0.1\n0.9\nB.1.3 Adadelta\nJ(W)\nMomentum", "J(W)\nMomentum\n variant on adagrad (for adaptive gradient). Even though our weights are indexed by\nlayer, input unit, and output unit, for simplicity here, just let \n be any weight in", "be any weight in\nthe network (we will do the same thing for all of them).\nThe sequence \n is a moving average of the square of the th component of the", "gradient. We square it in order to be insensitive to the sign\u2014we want to know\nwhether the magnitude is big or small. Then, we perform a gradient update to\nweight , but divide the step size by", ", which is larger when the surface is\nsteeper in direction  at point \n in weight space; this means that the step size\nwill be smaller when it\u2019s steep and larger when it\u2019s flat.", "Adam has become the default method of managing step sizes in neural networks.\nIt combines the ideas of momentum and adadelta. We start by writing moving", "averages of the gradient and squared gradient, which reflect estimates of the mean\nand variance of the gradient for weight :\nA problem with these estimates is that, if we initialize \n, they will", ", they will\nalways be biased (slightly too small). So we will correct for that bias by defining\nNote that \n is \n raised to the power , and likewise for \n. To justify these", ". To justify these\ncorrections, note that if we were to expand \n in terms of \n and\n, the coefficients would sum to 1. However, the coefficient behind\n is \n and since", "is \n and since \n, the sum of coefficients of nonzero terms is \n;\nhence the correction. The same justification holds for \n.\n\u2753 Study Question\nWj\ngt,j = \u2207WJ(Wt\u22121)j,\nGt,j = \u03b3 Gt\u22121,j + (1 \u2212\u03b3) g2\nt,j,", "t,j,\nWt,j = Wt\u22121,j \u2212\n\u03b7\n\u221aGt,j + \u03f5\ngt,j.\nGt,j\nj\nj\n\u221aGt,j + \u03f5\nj\nWt\u22121\nB.1.4 Adam\nj\ngt,j = \u2207WJ(Wt\u22121)j,\nmt,j = B1 mt\u22121,j + (1 \u2212B1) gt,j,\nvt,j = B2 vt\u22121,j + (1 \u2212B2) g2\nt,j.\nm0 = v0 = 0\n^mt,j =\nmt,j\n1 \u2212Bt\n1\n,", "mt,j\n1 \u2212Bt\n1\n,\n^vt,j =\nvt,j\n1 \u2212Bt\n2\n,\nWt,j = Wt\u22121,j \u2212\n\u03b7\n\u221a^vt,j + \u03f5\n^mt,j.\nBt\n1\nB1\nt\nBt\n2\nmt,j\nm0,j\ng0,j, g1,j, \u2026 , gt,j\nm0,j\nBt\n1\nm0,j = 0\n1 \u2212Bt\n1\nvt,j\nAlthough, interestingly, it may", "actually violate the convergence\nconditions of SGD:\narxiv.org/abs/1705.08292\n Define \n directly as a moving average of \n. What is the decay (\nparameter)?", "parameter)?\nEven though we now have a step size for each weight, and we have to update\nvarious quantities on each iteration of gradient descent, it\u2019s relatively easy to", "implement by maintaining a matrix for each quantity (\n, \n, \n, \n) in each layer\nof the network.\nB.2 Batch Normalization Details\nLet\u2019s think of the batch-normalization layer as taking", "as input and producing an\noutput \n. But now, instead of thinking of \n as an \n vector, we have to\nexplicitly think about handling a mini-batch of data of size \n all at once, so \n will\nbe an", "will\nbe an \n matrix, and so will the output \n.\nOur first step will be to compute the batchwise mean and standard deviation. Let \nbe the \n vector where\nand let \n be the \n vector where", "vector where\nThe basic normalized version of our data would be a matrix, element \n of which\nis\nwhere  is a very small constant to guard against division by zero.\nHowever, if we let these be our", "values, we really are forcing something too\nstrong on our data\u2014our goal was to normalize across the data batch, but not", "necessarily force the output values to have exactly mean 0 and standard deviation 1.\nSo, we will give the layer the opportunity to shift and scale the outputs by adding", "new weights to the layer. These weights are \n and \n, each of which is an \nvector. Using the weights, we define the final output to be\nThat\u2019s the forward pass. Whew!", "Now, for the backward pass, we have to do two things: given \n,\n^mt,j\ngt,j\n\u03b3\nm\u2113\nt v\u2113\nt g\u2113\nt g2\nt\n\u2113\nZ l\n\u02c6Z l\nZ l\nnl \u00d7 1\nK\nZ l\nnl \u00d7 K\n\u02c6Z l\n\u03bcl\nnl \u00d7 1\n\u03bcl\ni = 1\nK\nK\n\u2211\nj=1\nZ l\nij,\n\u03c3l\nnl \u00d7 1\n\u03c3l\ni =\n1\nK\nK\n\u2211", "\u03c3l\ni =\n1\nK\nK\n\u2211\nj=1\n(Z l\nij \u2212\u03bcl\ni)\n2\n.\n\ue001\n\ue000\n\u23b7\n(i, j)\nZ\nl\nij =\nZ l\nij \u2212\u03bcl\ni\n\u03c3l\ni + \u03f5\n,\n\u2013\n\u03f5\n\u02c6Z l\nGl\nBl\nnl \u00d7 1\n\u02c6Z l\nij = Gl\ni Z\nl\nij + Bl\ni.\n\u2013\n\u2202L\n\u2202\u02c6Z l\n Compute \n for back-propagation, and\nCompute \n and", "Compute \n and \n for gradient updates of the weights in this layer.\nSchematically, we have\nIt\u2019s hard to think about these derivatives in matrix terms, so we\u2019ll see how it works\nfor the components.", "contributes to \n for all data points  in the batch. So,\nSimilarly, \n contributes to \n for all data points  in the batch. Thus,\nNow, let\u2019s figure out how to do backprop. We can start schematically:", "And because dependencies only exist across the batch, but not across the unit\noutputs,\nThe next step is to note that\nAnd now that\nwhere \n if \n and 0 otherwise. We need two more pieces:", "Putting the whole thing together, we get\n\u2202L\n\u2202Z l\n\u2202L\n\u2202Gl\n\u2202L\n\u2202Bl\n\u2202L\n\u2202B = \u2202L\n\u2202\u02c6Z\n\u2202\u02c6Z\n\u2202B .\nBi\n\u02c6Zij\nj\n\u2202L\n\u2202Bi\n= \u2211\nj\n\u2202L\n\u2202\u02c6Zij\n\u2202\u02c6Zij\n\u2202Bi\n= \u2211\nj\n\u2202L\n\u2202\u02c6Zij\n.\nGi\n\u02c6Zij\nj\n\u2202L\n\u2202Gi\n= \u2211\nj\n\u2202L\n\u2202\u02c6Zij\n\u2202\u02c6Zij\n\u2202Gi\n= \u2211\nj\n\u2202L", "\u2202\u02c6Zij\n\u2202Gi\n= \u2211\nj\n\u2202L\n\u2202\u02c6Zij\nZij.\n\u2013\n\u2202L\n\u2202Z = \u2202L\n\u2202\u02c6Z\n\u2202\u02c6Z\n\u2202Z .\n\u2202L\n\u2202Zij\n=\nK\n\u2211\nk=1\n\u2202L\n\u2202\u02c6Zik\n\u2202\u02c6Zik\n\u2202Zij\n.\n\u2202\u02c6Zik\n\u2202Zij\n= \u2202\u02c6Zik\n\u2202Zik\n\u2202Zik\n\u2202Zij\n= Gi\n\u2202Zik\n\u2202Zij\n.\n\u2013\n\u2013\n\u2013\n\u2202Zik\n\u2202Zij\n= (\u03b4jk \u2212\u2202\u03bci\n\u2202Zij\n) 1\n\u03c3i\n\u2212Zik \u2212\u03bci\n\u03c32", ") 1\n\u03c3i\n\u2212Zik \u2212\u03bci\n\u03c32\ni\n\u2202\u03c3i\n\u2202Zij\n,\n\u2013\n\u03b4jk = 1\nj = k\n\u2202\u03bci\n\u2202Zij\n= 1\nK ,\n\u2202\u03c3i\n\u2202Zij\n= Zij \u2212\u03bci\nK \u03c3i\n.\n\u2202L\n\u2202Zij\n=\nK\n\u2211\nk=1\n\u2202L\n\u2202\u02c6Zik\nGi\n1\nK \u03c3i\n(K \u03b4jk \u22121 \u2212(Zik \u2212\u03bci)(Zij \u2212\u03bci)\n\u03c32\ni\n)."]