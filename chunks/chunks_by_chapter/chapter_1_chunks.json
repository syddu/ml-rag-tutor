["1 Introduction\nThe main focus of machine learning (ML) is making decisions or predictions based on\ndata. There are a number of other fields with significant overlap in technique, but", "difference in focus: in economics and psychology, the goal is to discover underlying\ncausal processes and in statistics it is to find a model that fits a data set well. In", "those fields, the end product is a model. In machine learning, we often fit models,\nbut as a means to the end of making good predictions or decisions.", "As ML methods have improved in their capability and scope, ML has become\narguably the best way\u2013measured in terms of speed, human engineering time, and", "robustness\u2013to approach many applications. Great examples are face detection,\nspeech recognition, and many kinds of language-processing tasks. Almost any", "application that involves understanding data or signals that come from the real\nworld can be nicely addressed using machine learning.", "One crucial aspect of machine learning approaches to solving problems is that\nhuman engineering plays an important role. A human still has to frame the problem:", "acquire and organize data, design a space of possible solutions, select a learning\nalgorithm and its parameters, apply the algorithm to the data, validate the resulting", "solution to decide whether it\u2019s good enough to use, try to understand the impact on\nthe people who will be affected by its deployment, etc. These steps are of great\nimportance.", "importance.\nThe conceptual basis of learning from data is the problem of induction: Why do we\nthink that previously seen data will help us predict the future? This is a serious long", "standing philosophical problem. We will operationalize it by making assumptions,\nsuch as that all training data are so-called i.i.d.(independent and identically", "distributed), and that queries will be drawn from the same distribution as the\ntraining data, or that the answer comes from a set of possible answers known in\nadvance.", "advance.\n6.390 - Intro to Machine Learning\nCourse Notes\nThis description is paraphrased\nfrom a post on 9/4/12 at\nandrewgelman.com.\nThis aspect is often undervalued.", "This means that the elements in the\nset are related in the sense that\nthey all come from the same\nunderlying probability\ndistribution, but not in other ways.\n\uf4611  Introduction\n\uf52a", "\uf4611  Introduction\n\uf52a\n In general, we need to solve these two problems:\nestimation: When we have data that are noisy reflections of some underlying", "quantity of interest, we have to aggregate the data and make estimates or\npredictions about the quantity. How do we deal with the fact that, for example,", "the same treatment may end up with different results on different trials? How\ncan we predict how well an estimate may compare to future results?", "generalization: How can we predict results of a situation or experiment that\nwe have never encountered before in our data set?", "We can describe problems and their solutions using six characteristics, three of\nwhich characterize the problem and three of which characterize the solution:", "1. Problem class: What is the nature of the training data and what kinds of\nqueries will be made at testing time?\n2. Assumptions: What do we know about the source of the data or the form of", "the solution?\n3. Evaluation criteria: What is the goal of the prediction or estimation system?\nHow will the answers to individual queries be evaluated? How will the overall", "performance of the system be measured?\n4. Model type: Will an intermediate model of the world be made? What aspects\nof the data will be modeled in different variables/parameters? How will the", "model be used to make predictions?\n5. Model class: What particular class of models will be used? What criterion will\nwe use to pick a particular model from the model class?", "6. Algorithm: What computational process will be used to fit the model to the\ndata and/or to make predictions?\nWithout making some assumptions about the nature of the process generating the", "data, we cannot perform generalization. In the following sections, we elaborate on\nthese ideas.\n1.1 Problem class\nThere are many different problem classes in machine learning. They vary according to", "what kind of data is provided and what kind of conclusions are to be drawn from it.\nFive standard problem classes are described below, to establish some notation and\nterminology.", "terminology.\nIn this course, we will focus on classification and regression (two examples of\nsupervised learning), and we will touch on reinforcement learning, sequence\nlearning, and clustering.", "For example, the same treatment\nmay end up with different results\non different trials. How can we\npredict how well an estimate\ncompares to future results?\nDon\u2019t feel you have to memorize", "all these kinds of learning, etc. We\njust want you to have a very high-\n The idea of supervised learning is that the learning system is given inputs and told", "which specific outputs should be associated with them. We divide up supervised\nlearning based on whether the outputs are drawn from a small finite set", "(classification) or a large finite ordered set or continuous set (regression).\nFor a regression problem, the training data \n is in the form of a set of  pairs:\nwhere", "where \n represents an input, most typically a -dimensional vector of real and/or\ndiscrete values, and \n is the output to be predicted, in this case a real-number. The", "values are sometimes called target values.\nThe goal in a regression problem is ultimately, given a new input value \n, to\npredict the value of", ". Regression problems are a kind of supervised learning,\nbecause the desired output \n is specified for each of the training examples \n.", ".\nA classification problem is like regression, except that the values that \n can take\ndo not have an order. The classification problem is binary or two-class if \n (also", "(also\nknown as the class) is drawn from a set of two possible values; otherwise, it is called\nmulti-class.\nUnsupervised learning doesn\u2019t involve learning a function from inputs to outputs", "based on a set of input-output pairs. Instead, one is given a data set and generally\nexpected to find some patterns or structure inherent in it.\nGiven samples", "Given samples \n, the goal is to find a partitioning (or \u201cclustering\u201d)\nof the samples that groups together similar samples. There are many different", "objectives, depending on the definition of the similarity between samples and\nexactly what criterion is to be used (e.g., minimize the average distance between", "elements inside a cluster and maximize the average distance between elements\nacross clusters). Other methods perform a \u201csoft\u201d clustering, in which samples may", "be assigned 0.9 membership in one cluster and 0.1 in another. Clustering is\nsometimes used as a step in the so-called density estimation (described below), and", "sometimes to find useful structure or influential features in data.\n1.1.1 Supervised learning\n1.1.1.1 Regression\nDtrain\nn\nDtrain = {(x(1), y(1)), \u2026 , (x(n), y(n))},\nx(i)\nd\ny(i)\ny\nx(n+1)\ny(n+1)\ny(i)", "x(n+1)\ny(n+1)\ny(i)\nx(i)\n1.1.1.2 Classification\ny(i)\ny(i)\n1.1.2 Unsupervised learning\n1.1.2.1 Clustering\nx(1), \u2026 , x(n) \u2208Rd\nlevel view of (part of) the breadth\nof the field.\nMany textbooks use \n and", "and \ninstead of \n and \n. We find that\nnotation somewhat difficult to\nmanage when \n is itself a vector\nand we need to talk about its\nelements. The notation we are\nusing is standard in some other", "parts of the ML literature.\nxi\nti\nx(i)\ny(i)\nx(i)\n Given samples \n drawn i.i.d. from some distribution \n, the\ngoal is to predict the probability \n of an element drawn from the same", "distribution. Density estimation sometimes plays a role as a \u201csubroutine\u201d in the\noverall learning method for supervised learning, as well.\nGiven samples", "Given samples \n, the problem is to re-represent them as points in\na -dimensional space, where \n. The goal is typically to retain information in", "the data set that will, e.g., allow elements of one class to be distinguished from\nanother.\nDimensionality reduction is a standard technique that is particularly useful for", "visualizing or understanding high-dimensional data. If the goal is ultimately to\nperform regression or classification on the data after the dimensionality is reduced,", "it is usually best to articulate an objective for the overall prediction problem rather\nthan to first do dimensionality reduction without knowing which dimensions will", "be important for the prediction task.\nIn sequence learning, the goal is to learn a mapping from input sequences \nto output sequences \n. The mapping is typically represented as a state", "machine, with one function \n used to compute the next hidden internal state given\nthe input, and another function \n used to compute the output given the current\nhidden state.", "hidden state.\nIt is supervised in the sense that we are told what output sequence to generate for\nwhich input sequence, but the internal functions have to be learned by some", "method other than direct supervision, because we don\u2019t know what the hidden\nstate sequence is.\nIn reinforcement learning, the goal is to learn a mapping from input values", "(typically assumed to be states of an agent or system; for now, think e.g. the velocity\nof a moving car) to output values (typically we want control actions; for now, think", "e.g. if to accelerate or hit the brake). However, we need to learn the mapping\nwithout a direct supervision signal to specify which output values are best for a", "particular input; instead, the learning problem is framed as an agent interacting\nwith an environment, in the following setting:\nThe agent observes the current state \n.\nIt selects an action", "1.1.2.2 Density estimation\nx(1), \u2026 , x(n) \u2208Rd\nPr(X)\nPr(x(n+1))\n1.1.2.3 Dimensionality reduction\nx(1), \u2026 , x(n) \u2208RD\nd\nd < D\n1.1.3 Sequence learning\nx0, \u2026 , xn\ny1, \u2026 , ym\nfs\nfo", "y1, \u2026 , ym\nfs\nfo\n1.1.4 Reinforcement learning\nst\nat.\n It receives a reward, \n, which typically depends on \n and possibly \n.\nThe environment transitions probabilistically to a new state, \n, with a", ", with a\ndistribution that depends only on \n and \n.\nThe agent observes the current state, \n.\nThe goal is to find a policy , mapping  to , (that is, states to actions) such that", "some long-term sum or average of rewards  is maximized.\nThis setting is very different from either supervised learning or unsupervised", "learning, because the agent\u2019s action choices affect both its reward and its ability to\nobserve the environment. It requires careful consideration of the long-term effects of", "actions, as well as all of the other issues that pertain to supervised learning.\nThere are many other problem settings. Here are a few.", "In semi-supervised learning, we have a supervised-learning training set, but there\nmay be an additional set of \n values with no known \n. These values can still be", "used to improve learning performance (if they are drawn from \n that is the\nmarginal of \n that governs the rest of the data set).\nIn active learning, it is assumed to be expensive to acquire a label", "(imagine\nasking a human to read an x-ray image), so the learning algorithm can sequentially\nask for particular inputs \n to be labeled, and must carefully select queries in order", "to learn as effectively as possible while minimizing the cost of labeling.\nIn transfer learning (also called meta-learning), there are multiple tasks, with data", "drawn from different, but related, distributions. The goal is for experience with\nprevious tasks to apply to learning a current task in a way that requires decreased\nexperience with the new task.", "1.2 Assumptions\nThe kinds of assumptions that we can make about the data source or the solution\ninclude:\nThe data are independent and identically distributed (i.i.d.).", "The data are generated by a Markov chain (i.e. outputs only depend only on\nthe current state, with no additional memory).\nThe process generating the data might be adversarial.\nrt\nst\nat\nst+1\nst\nat", "rt\nst\nat\nst+1\nst\nat\nst+1\n\u2026\n\u03c0\ns\na\nr\n1.1.5 Other settings\nx(i)\ny(i)\nPr(X)\nPr(X, Y )\ny(i)\nx(i)\n The \u201ctrue\u201d model that is generating the data can be perfectly described by one", "of some particular set of hypotheses.\nThe effect of an assumption is often to reduce the \u201csize\u201d or \u201cexpressiveness\u201d of the", "space of possible hypotheses and therefore reduce the amount of data required to\nreliably identify an appropriate hypothesis.\n1.3 Evaluation criteria", "Once we have specified a problem class, we need to say what makes an output or\nthe answer to a query good, given the training data. We specify evaluation criteria", "at two levels: how an individual prediction is scored, and how the overall behavior\nof the prediction or estimation system is scored.", "The quality of predictions from a learned model is often expressed in terms of a loss\nfunction. A loss function \n tells you how much you will be penalized for", "making a guess  when the answer is actually . There are many possible loss\nfunctions. Here are some frequently used examples:\n0-1 Loss applies to predictions drawn from finite domains.\nSquared loss", "Squared loss\nAbsolute loss\nAsymmetric loss Consider a situation in which you are trying to predict\nwhether someone is having a heart attack. It might be much worse to predict", "\u201cno\u201d when the answer is really \u201cyes\u201d, than the other way around.\nAny given prediction rule will usually be evaluated based on multiple predictions", "and the loss of each one. At this level, we might be interested in:\nMinimizing expected loss over all the predictions (also known as risk)\nMinimizing maximum loss: the loss of the worst prediction", "Minimizing or bounding regret: how much worse this predictor performs than\nthe best one drawn from some class\nL(g, a)\ng\na\nL(g, a) = {0\nif g = a\n1\notherwise\nL(g, a) = (g \u2212a)2\nL(g, a) = |g \u2212a|", "L(g, a) = |g \u2212a|\nL(g, a) =\n\u23a7\n\u23aa\n\u23a8\n\u23aa\n\u23a9\n1\nif g = 1 and a = 0\n10\nif g = 0 and a = 1\n0\notherwise\n Characterizing asymptotic behavior: how well the predictor will perform in the", "limit of infinite training data\nFinding algorithms that are probably approximately correct: they probably\ngenerate a hypothesis that is right most of the time.", "There is a theory of rational agency that argues that you should always select the\naction that minimizes the expected loss. This strategy will, for example, make you the", "most money in the long run, in a gambling setting. As mentioned above, expected\nloss is also sometimes called risk in ML literature, but that term means other things", "in economics or other parts of decision theory, so be careful...it\u2019s risky to use it. We\nwill, most of the time, concentrate on this criterion.\n1.4 Model type", "1.4 Model type\nRecall that the goal of a ML system is typically to estimate or generalize, based on\ndata provided. Below, we examine the role of model-making in machine learning.", "In some simple cases, in response to queries, we can generate predictions directly\nfrom the training data, without the construction of any intermediate model, or more", "precisely, without the learning of any parameters.\nFor example, in regression or classification, we might generate an answer to a new", "query by averaging answers to recent queries, as in the nearest neighbor method.\nThis two-step process is more typical:", "1. \u201cFit\u201d a model (with some a-prior chosen parameterization) to the training data\n2. Use the model directly to make predictions", "In the parametric models setting of regression or classification, the model will be\nsome hypothesis or prediction rule \n for some functional form . The", "term hypothesis has its roots in statistical learning and the scientific method, where\nmodels or hypotheses about the world are tested against real data, and refined with", "more evidence, observations, or insights. Note that the parameters themselves are\nonly part of the assumptions that we\u2019re making about the world. The model itself is", "a hypothesis that will be refined with more evidence.\nThe idea is that \n is a set of one or more parameter values that will be determined", "by fitting the model to the training data and then be held fixed during testing.\nGiven a new \n, we would then make the prediction \n.\n1.4.1 Non-parametric models\n1.4.2 Parametric models\ny = h(x; \u0398)\nh", "y = h(x; \u0398)\nh\n\u0398\nx(n+1)\nh(x(n+1); \u0398)\n The fitting process is often articulated as an optimization problem: Find a value of\n that minimizes some criterion involving", "and the data. An optimal strategy, if\nwe knew the actual underlying distribution on our data, \n would be to\npredict the value of  that minimizes the expected loss, which is also known as the", "test error. If we don\u2019t have that actual underlying distribution, or even an estimate of\nit, we can take the approach of minimizing the training error: that is, finding the", "prediction rule  that minimizes the average loss on our training data set. So, we\nwould seek \n that minimizes\nwhere the loss function \n measures how bad it would be to make a guess of", "when the actual value is .\nWe will find that minimizing training error alone is often not a good choice: it is\npossible to emphasize fitting the current data too strongly and end up with a", "hypothesis that does not generalize well when presented with new  values.\n1.5 Model class and parameter fitting\nA model class \n is a set of possible models, typically parameterized by a vector of", "parameters \n. What assumptions will we make about the form of the model? When\nsolving a regression problem using a prediction-rule approach, we might try to find\na linear function", "a linear function \n that fits our data well. In this example, the\nparameter vector \n.\nFor problem types such as classification, there are huge numbers of model classes", "that have been considered...we\u2019ll spend much of this course exploring these model\nclasses, especially neural networks models. We will almost completely restrict our", "attention to model classes with a fixed, finite number of parameters. Models that\nrelax this assumption are called \u201cnon-parametric\u201d models.", "How do we select a model class? In some cases, the ML practitioner will have a\ngood idea of what an appropriate model class is, and will specify it directly. In other", "cases, we may consider several model classes and choose the best based on some\nobjective function. In such situations, we are solving a model selection problem:", "model-selection is to pick a model class \n from a (usually finite) set of possible\nmodel classes, whereas model fitting is to pick a particular model in that class,", "specified by (usually continuous) parameters \n.\n1.6 Algorithm\nOnce we have described a class of models and a way of scoring a model given data,", "we have an algorithmic problem: what sequence of computational instructions\nshould we run in order to find a good model from our class? For example,\n\u0398\n\u0398\nPr(X, Y )\ny\nh\n\u0398\nEtrain(h; \u0398) = 1\nn\nn\n\u2211\ni=1", "n\nn\n\u2211\ni=1\nL(h(x(i); \u0398), y(i)) ,\nL(g, a)\ng\na\nx\nM\n\u0398\nh(x; \u03b8, \u03b80) = \u03b8Tx + \u03b80\n\u0398 = (\u03b8, \u03b80)\nM\n\u0398\n determining the parameter vector which minimizes the training error might be", "done using a familiar least-squares minimization algorithm, when the model  is a\nfunction being fit to some data .\nSometimes we can use software that was designed, generically, to perform", "optimization. In many other cases, we use algorithms that are specialized for ML\nproblems, or for particular hypotheses classes. Some algorithms are not easily seen", "as trying to optimize a particular criterion. In fact, a historically important method\nfor finding linear classifiers, the perceptron algorithm, has this character.\nh\nx"]