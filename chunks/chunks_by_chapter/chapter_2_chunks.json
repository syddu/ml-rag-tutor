["We had legacy PDF notes that used mixed conventions for data matrices: \u201ceach row as a\ndata point\u201d and \u201ceach column as a data point\u201d.\nWe are standardizing to \u201ceach row as a data point.\u201d Thus,", "aligns with \n in the PDF\nnotes if you\u2019ve read those. If you spot inconsistencies or experience any confusion, please\nraise an issue. Thanks!", "Regression is an important machine-learning problem that provides a good starting\npoint for diving deeply into the field.\n2.1 Problem formulation", "A hypothesis  is employed as a model for solving the regression problem, in that it\nmaps inputs  to outputs ,\nwhere \n (i.e., a length  column vector of real numbers), and \n (i.e., a real", "(i.e., a real\nnumber). Real life rarely gives us vectors of real numbers; the  we really want to\ntake as input is usually something like a song, image, or person. In that case, we\u2019ll", "have to define a function \n, whose range is \n, where  represents features of ,\nlike a person\u2019s height or the amount of bass in a song, and then let the", ". In much of the following, we\u2019ll omit explicit mention of  and assume that the \nare in \n, but you should always have in mind that some additional process was", "almost surely required to go from the actual input examples to their feature\nrepresentation, and we\u2019ll talk a lot more about features later in the course.", "Regression is a supervised learning problem, in which we are given a training dataset\nof the form\nwhich gives examples of input values \n and the output values \n that should be", "that should be\nassociated with them. Because  values are real-valued, our hypotheses will have\nthe form\nThis is a good framework when we want to predict a numerical quantity, like", "height, stock value, etc., rather than to divide the inputs into discrete categories.\n2  Regression\nWarning\nX\n~X\nh\nx\ny\nx \u2192\n\u2192y ,\nh\nx \u2208Rd\nd\ny \u2208R\nx\n\u03c6(x)\nRd\n\u03c6\nx\nh : \u03c6(x) \u2192R\n\u03c6\nx(i)\nRd", "\u03c6\nx(i)\nRd\nDtrain = {(x(1), y(1)), \u2026 , (x(n), y(n))} ,\nx(i)\ny(i)\ny\nh : Rd \u2192R .\n\u201cRegression,\u201d in common parlance,\nmeans moving backwards. But this\nis forward progress!", "Real life rarely gives us vectors of\nreal numbers. The  we really want\nto take as input is usually\nsomething like a song, image, or\nperson. In that case, we\u2019ll have to\ndefine a function \n whose", "whose\nrange is \n, where  represents\nfeatures of  (e.g., a person\u2019s height\nor the amount of bass in a song).\nx\n\u03c6(x)\nRd\n\u03c6\nx\n\uf4612  Regression\n\uf52a\n1", "\uf4612  Regression\n\uf52a\n1\n What makes a hypothesis useful? That it works well on new data\u2014that is, it makes\ngood predictions on examples it hasn\u2019t seen.", "However, we don\u2019t know exactly what data this hypothesis might be tested on in\nthe real world. So, we must assume a connection between the training data and", "testing data. Typically, the assumption is that they are drawn independently from\nthe same probability distribution.\nTo make this discussion more concrete, we need a loss function to express how", "unhappy we are when we guess an output  given an input  for which the desired\noutput was .\nGiven a training set \n and a hypothesis  with parameters \n, the training error", "of  can be defined as the average loss on the training data:\nThe training error of  gives us some idea of how well it characterizes the", "relationship between  and  values in our data, but it isn\u2019t the quantity we most\ncare about. What we most care about is test error:\non", "on \n new examples that were not used in the process of finding the hypothesis.\nIt might be worthwhile to stare at the two errors and think about what\u2019s the difference.\nFor example, notice how", "is no longer a variable in the testing error? This is because, in\nevaluating the testing error, the parameters will have been \u201cpicked\u201d or \u201cfixed\u201d already.", "For now, we will try to find a hypothesis with small training error (later, with some\nadded criteria) and try to make some design choices so that it generalizes well to new", "data, meaning that it also has a small test error.\n2.2 Regression as an optimization problem\nGiven data, a loss function, and a hypothesis class, we need a method for finding a", "good hypothesis in the class. One of the most general ways to approach this\nproblem is by framing the machine learning problem as an optimization problem.", "One reason for taking this approach is that there is a rich area of math and\nalgorithms studying and developing efficient methods for solving optimization\ng\nx\na\nDtrain\nh\n\u0398\nh\nEtrain(h; \u0398) = 1\nn\nn\n\u2211", "n\nn\n\u2211\ni=1\nL(h(x(i); \u0398), y(i)) .\n(2.1)\nh\nx\ny\nEtest(h) = 1\nn\u2032\nn+n\u2032\n\u2211\ni=n+1\nL(h(x(i)), y(i)) ,\nn\u2032\nNote\n\u0398\nThis process of converting our data\ninto a numerical form is often", "referred to as data pre-processing.\nThen  maps \n to .\nIn much of the following, we\u2019ll\nomit explicit mention of  and\nassume that the \n are in \n.\nHowever, you should always", "remember that some additional\nprocess was almost surely required\nto go from the actual input\nexamples to their feature\nrepresentation. We will discuss\nfeatures more later in the course.\nh\n\u03c6(x)\nR\n\u03c6", "h\n\u03c6(x)\nR\n\u03c6\nx(i)\nRd\nMy favorite analogy is to problem\nsets. We evaluate a student\u2019s ability\nto generalize by putting questions\non the exam that were not on the\nhomework (training set).", "problems, and lots of very good software implementations of these methods. So, if\nwe can turn our problem into one of these problems, then there will be a lot of work\nalready done for us!", "We begin by writing down an objective function \n, where \n stands for all the\nparameters in our model (i.e., all possible choices over parameters). We often write", "to make clear the dependence on the data \n.\nThe objective function describes how we feel about possible hypotheses \n. We\ngenerally look for parameter values \n that minimize the objective function:", "In the most general case, there is not a guarantee that there exists a unique set of\nparameters which minimize the objective function. However, we will ignore that for", "now. A very common form for a machine-learning objective is:\nThe loss measures how unhappy we are about the prediction \n for the pair", "for the pair\n. Minimizing this loss improves prediction accuracy. The regularizer \nis an additional term that encourages the prediction to remain general, and the", "constant  adjusts the balance between fitting the training examples and\ngeneralizing to unseen examples. We will discuss this balance and the idea of\nregularization further in Section 2.7.", "2.3 Linear regression\nTo make this discussion more concrete, we need to provide a hypothesis class and a\nloss function.\nWe begin by picking a class of hypotheses \n that might provide a good set of", "possible models for the relationship between  and  in our data. We start with a\nvery simple class of linear hypotheses for regression:\nwhere the model parameters are \n. In one dimension (\n), this", "), this\ncorresponds to the familiar slope-intercept form \n of a line. In two\ndimesions (\n), this corresponds to a plane. In higher dimensions, this model", "describes a hyperplane. This hypothesis class is both simple to study and very\npowerful, and will serve as the basis for many other important techniques (even\nneural networks!).\nJ(\u0398)\n\u0398\nJ(\u0398; D)\nD\n\u0398\n\u0398", "\u0398\nJ(\u0398; D)\nD\n\u0398\n\u0398\n\u0398\u2217= arg min\n\u0398 J(\u0398) .\nJ(\u0398) =\n1\nn\nn\n\u2211\ni=1\nL(h(x(i); \u0398), y(i))\nloss\n+\n\u03bb\nnon-negative constant\nR(\u0398).\n\u239b\n\u239c\n\u239d\n\ue152\n\ue154\n\ue151\ue150\n\ue154\n\ue153\n\u239e\n\u239f\n\u23a0\n\ue152\n\ue154\n\ue151\ue150\n\ue154\n\ue153\n(2.2)\nh(x(i); \u0398)\n(x(i), y(i))\nR(\u0398)\n\u03bb\nH\nx\ny", "R(\u0398)\n\u03bb\nH\nx\ny\ny = h(x; \u03b8, \u03b80) = \u03b8Tx + \u03b80 ,\n(2.3)\n\u0398 = (\u03b8, \u03b80)\nd = 1\ny = mx + b\nd = 2\nDon\u2019t be too perturbed by the\nsemicolon where you expected to\nsee a comma! It\u2019s a mathematical", "way of saying that we are mostly\ninterested in this as a function of\nthe arguments before the ; , but we\nshould remember there\u2019s a\ndependence on the stuff after it as\nwell.", "well.\n For now, our objective in linear regression is to find a hypothesis that goes as close\nas possible, on average, to all of our training data. We define a loss function to", "describe how to evaluate the quality of the predictions our hypothesis is making,\nwhen compared to the \u201ctarget\u201d  values in the data set. The choice of loss function", "is part of modeling your domain. In the absence of additional information about a\nregression problem, we typically use squared loss:\nwhere", "where \n is our \u201cguess\u201d from the hypothesis, or the hypothesis\u2019 prediction,\nand  is the \u201cactual\u201d observation (in other words, here  is being used equivalently", "as ). With this choice of squared loss, the average loss as generally defined in\nEquation 2.1 will become the so-called mean squared error (MSE).", "Applying the general optimization framework to the linear regression hypothesis\nclass of Equation 2.3 with squared loss and no regularization, our objective is to find\nvalues for", "values for \n that minimize the MSE:\nresulting in the solution:\nFor one-dimensional data (\n), this corresponds to fitting a line to data. For", ", this hypothesis represents a -dimensional hyperplane embedded in a\n-dimensional space (the input dimension plus the  dimension).", "For example, in the left plot below, we can see data points with labels  and input\ndimensions \n and \n. In the right plot below, we see the result of fitting these", "points with a two-dimensional plane that resides in three dimensions. We interpret\nthe plane as representing a function that provides a  value for any input \n.\ny\nL(g, a) = (g \u2212a)2 .\ng = h(x)\na\na\ny", "g = h(x)\na\na\ny\n\u0398 = (\u03b8, \u03b80)\nJ(\u03b8, \u03b80) = 1\nn\nn\n\u2211\ni=1\n(\u03b8Tx(i) + \u03b80 \u2212y(i))\n2\n,\n(2.4)\n\u03b8\u2217, \u03b8\u2217\n0 = arg min\n\u03b8,\u03b80 J(\u03b8, \u03b80) .\n(2.5)\nd = 1\nd > 1\nd\n(d + 1)\ny\ny\nx1\nx2\ny\n(x1, x2)\nThe squared loss penalizes guesses", "that are too high the same amount\nas it penalizes guesses that are too\nlow, and has a good mathematical\njustification in the case that your\ndata are generated from an", "underlying linear hypothesis with\nthe so-called Gaussian-\ndistributed noise added to the \nvalues. But there are applications\nin which other losses would be\nbetter, and much of the framework", "we discuss can be applied to\ndifferent loss functions, although\nthis one has a form that also makes\nit particularly computationally\nconvenient.\nWe won\u2019t get into the details of", "Gaussian distribution in our class;\nbut it\u2019s one of the most important\ndistributions and well-worth\nstudying closely at some point.\nOne obvious fact about Gaussian is", "that it\u2019s symmetric; this is in fact\none of the reasons squared loss\ny\n A richer class of hypotheses can be obtained by performing a non-linear feature", "transformation before doing the regression, as we will later see, but it will still end\nup that we have to solve a linear regression problem.\n2.4 A gloriously simple linear regression\nalgorithm", "algorithm\nOkay! Given the objective in Equation 2.4, how can we find good values of  and \n? We\u2019ll study several general-purpose, efficient, interesting algorithms. But before", "we do that, let\u2019s start with the simplest one we can think of: guess a whole bunch ( )\nof different values of  and \n, see which one has the smallest error on the training set,\nand return it.", "and return it.\nAlgorithm 2.1 Random-Regression\nRequire: Data , integer \nfor \n to  do\nRandomly generate hypothesis \nend for\nLet \nreturn", "Let \nreturn \nThis seems kind of silly, but it\u2019s a learning algorithm, and it\u2019s not completely\nuseless.\n\u2753 Study Question", "\u2753 Study Question\nIf your data set has  data points, and the dimension of the  values is , what is\nthe size of an individual \n?\n\u2753 Study Question", "?\n\u2753 Study Question\nHow do you think increasing the number of guesses  will change the training\nerror of the resulting hypothesis?\n2.5 Analytical solution: ordinary least squares", "One very interesting aspect of the problem of finding a linear hypothesis that\nminimizes mean squared error is that we can find a closed-form formula for the", "answer! This general problem is often called the ordinary least squares (ols).\nEverything is easier to deal with if we first ignore the offset \n. So, suppose for now,\nwe have, simply,\n\u03b8\n\u03b80\nk\n\u03b8\n\u03b80\nD\nk", "\u03b8\n\u03b80\nk\n\u03b8\n\u03b80\nD\nk\n1:\ni = 1\nk\n2:\n\u03b8i, \u03b80(i)\n3:\n4:\ni = arg minj J(\u03b8(j), \u03b80(j); D)\n5:\n\u03b8(i), \u03b80(i)\nn\nx\nd\n\u03b8(i)\nk\n\u03b80\ny = \u03b8Tx .\n(2.6)\nworks well under Gaussian\nsettings, as the loss is also\nsymmetric.", "symmetric.\nthis corresponds to a hyperplane\nthat goes through the origin.\n In this case, the objective becomes\nWe approach this just like a minimization problem from calculus homework: take", "the derivative of  with respect to , set it to zero, and solve for . There are\nadditional steps required, to check that the resulting  is a minimum (rather than a", "maximum or an inflection point) but we won\u2019t work through that here. It is possible\nto approach this problem by:\nFinding \n for  in \n,\nConstructing a set of  equations of the form \n, and", ", and\nSolving the system for values of \n.\nThat works just fine. To get practice for applying techniques like this to more", "complex problems, we will work through a more compact (and cool!) matrix view.\nAlong the way, it will be helpful to collect all of the derivatives in one vector. In", "particular, the gradient of  with respect to  is following column vector of length :\n\u2753 Study Question\nWork through the next steps and check your answer against ours below.", "We can think of our training data in terms of matrices \n and \n, where each row of\n is an example, and each row (or rather, element) of \n is the corresponding target\noutput value:\n\u2753 Study Question", "\u2753 Study Question\nWhat are the dimensions of \n and \n?\nJ(\u03b8) = 1\nn\nn\n\u2211\ni=1\n(\u03b8Tx(i) \u2212y(i))\n2\n.\n(2.7)\nJ\n\u03b8\n\u03b8\n\u03b8\n\u2202J/\u2202\u03b8k\nk\n1, \u2026 , d\nk\n\u2202J/\u2202\u03b8k = 0\n\u03b8k\nJ\n\u03b8\nd\n\u2207\u03b8J =\n.\n\u23a1\n\u23a2\n\u23a3\n\u2202J/\u2202\u03b81\n\u22ee\n\u2202J/\u2202\u03b8d\n\u23a4\n\u23a5\n\u23a6\nX\nY\nX\nY\nX =\nY =\n.", "\u23a6\nX\nY\nX\nY\nX =\nY =\n.\n\u23a1\n\u23a2\n\u23a3\nx(1)\n1\n\u2026\nx(1)\nd\n\u22ee\n\u22f1\n\u22ee\nx(n)\n1\n\u2026\nx(n)\nd\n\u23a4\n\u23a5\n\u23a6\n\u23a1\n\u23a2\n\u23a3\ny(1)\n\u22ee\ny(n)\n\u23a4\n\u23a5\n\u23a6\nX\nY\n Now we can write\nand using facts about matrix/vector calculus, we get", "Setting this equal to zero and solving for  yields the final closed-form solution:\nand the dimensions work out! So, given our data, we can directly compute the", "linear regression that minimizes mean squared error. That\u2019s pretty awesome!\nNow, how do we deal with the offset? We augment the original feature vector with", "a \u201cfake\u201d feature of value 1, and add a corresponding parameter \n to the  vector.\nThat is, we define columns vectors \n such that,\nwhere the \u201caug\u201d denotes that \n have been augmented.", "Then we can now write the linear hypothesis as if there is no offset,\nWe can do this \u201cappending a fake feature of 1\u201d to all data points to form the\naugmented data matrix", "where  as an -by  vector of all one. Then use the formula in Equation 2.8 to find\nthe \n that minimizes the mean squared error.\nJ(\u03b8) = 1\nn\nn\n\u2211\ni=1\n(\u03b8Tx(i) \u2212y(i))2 = 1\nn (X\u03b8 \u2212Y )T(X\u03b8 \u2212Y ).\n\u2207\u03b8J(\u03b8) = 1", "\u2207\u03b8J(\u03b8) = 1\nn \u2207\u03b8 [(X\u03b8)TX\u03b8 \u2212Y TX\u03b8 \u2212(X\u03b8)TY + Y TY ]\n= 2\nn (XTX\u03b8 \u2212XTY ).\n\u03b8\n\u03b8\u2217= (XTX)\n\u22121XTY\n(2.8)\n\u03b80\n\u03b8\nxaug, \u03b8aug \u2208Rd+1\nxaug =\n,\n\u03b8aug =\n\u23a1\n\u23a2\n\u23a3\nx1\nx2\n\u22ee\nxd\n1\n\u23a4\n\u23a5\n\u23a6\n\u23a1\n\u23a2\n\u23a3\n\u03b81\n\u03b82\n\u22ee\n\u03b8d\n\u03b80\n\u23a4\n\u23a5\n\u23a6\n\u03b8, x", "\u22ee\n\u03b8d\n\u03b80\n\u23a4\n\u23a5\n\u23a6\n\u03b8, x\ny = h(xaug; \u03b8aug) = \u03b8T\naugxaug\n(2.9)\nXaug\nXaug =\n= [\n]\n\u23a1\n\u23a2\n\u23a3\nx(1)\n1\n\u2026\nx(1)\nd\n1\n\u22ee\n\u22f1\n\u22ee\n\u22ee\nx\n(n)\n1\n\u2026\nx\n(n)\nd\n1\n\u23a4\n\u23a5\n\u23a6\nX\n\ud835\udfd9\n\ud835\udfd9\nn\n1\n\u03b8aug\nSee Appendix A if you need some", "help finding this gradient.\nHere are two related alternate\nangles to view this formula, for\nintuition\u2019s sake:\n1. Note that\n is the\npseudo-inverse of \n. Thus, \n\u201cpseudo-solves\u201d", "\u201cpseudo-solves\u201d \n(multiply both sides of this on\nthe left by \n).\n2. Note that\nis the projection matrix onto\nthe column space of \n. Thus,\n solves \n.\n(X TX)\u22121X T = X +\n:\nX\n\u03b8\u2217\nX\u03b8 = Y\nX +", ":\nX\n\u03b8\u2217\nX\u03b8 = Y\nX +\nX(X TX)\u22121X T = projcol(X)\nX\n\u03b8\u2217\nX\u03b8 = projcol(X)Y\nThis is a very special case where\nwe can find the solution in closed\nform. In general, we will need to\nuse iterative optimization", "algorithms to find the best\nparameters. Also, this process of\nsetting the graident/derivatives to\nzero and solving for the\nparameters works out in this\nproblem. But there can be", "exceptions to this rule, and we will\ndiscuss them later in the course.\nBut of course, the constant offset is\nnot really gone, it\u2019s just hidden in\nthe augmentation.\n \u2753 Study Question", "\u2753 Study Question\nStop and prove to yourself that adding that extra feature with value 1 to every\ninput vector and getting rid of the \n parameter, as done in Equation 2.9 is", "equivalent to our original model Equation 2.3.\n2.6 Centering\nIn fact, augmenting a \u201cfake\u201d feature of 1, as described above, is also useful for an", "important idea: namely, why utilizing the so-called centering eliminates the need\nfor fitting an intercept, and thereby offers an alternative way to avoid dealing with\n directly.", "directly.\nBy centering, we mean subtracting the average (mean) of each feature from all data\npoints, and we apply the same operation to the labels. For an example of a dataset", "before and after centering, see here\nThe idea is that, with centered dataset, even if we were to search for an offset term", ", it would naturally fall out to be 0. Intuitively, this makes sense \u2013 if a dataset is\ncentered around the origin, it seems natural that the best fitting plane would go\nthrough the origin.", "through the origin.\nLet\u2019s see how this works out mathematically. First, for a centered dataset, two claims\nimmediately follow (recall that  is an -by-1 vector of all ones):\n1. Each column of", "1. Each column of \n sums up to zero, that is, \n.\n2. Similarly, the mean of the labels is 0, so \n.\nRecall that our ultimate goal is to find an optimal fitting hyperplane, parameterized\nby  and", "by  and \n. In other words, we aim to find \n which at this point, involves\nsimply plugging \n into Equation 2.8.\n\u03b80\n\u03b80\n\u03b80\n\ud835\udfd9\nn\nX\nXT\ud835\udfd9= 0\nY T\ud835\udfd9= \ud835\udfd9TY = 0\n\u03b8\n\u03b80\n\u03b8aug,\nXaug = [\n]\nX\n\ud835\udfd9\n1\n Indeed, the optimal", "naturally falls out to be 0.\n2.7 Regularization\nThe objective function of Equation 2.2 balances (training-data) memorization,", "induced by the loss term, with generalization, induced by the regularization term.\nHere, we address the need for regularization specifically for linear regression, and", "show how this can be realized using one popular regularization technique called\nridge regression.\nIf all we cared about was finding a hypothesis with small loss on the training data,", "we would have no need for regularization, and could simply omit the second term\nin the objective. But remember that our ultimate goal is to perform well on input", "values that we haven\u2019t trained on! It may seem that this is an impossible task, but\nhumans and machine-learning methods do this successfully all the time. What", "allows generalization to new input values is a belief that there is an underlying\nregularity that governs both the training and testing data. One way to describe an", "assumption about such a regularity is by choosing a limited class of possible\nhypotheses. Another way to do this is to provide smoother guidance, saying that,", "within a hypothesis class, we prefer some hypotheses to others. The regularizer\narticulates this preference and the constant  says how much we are willing to trade", "off loss on the training data versus preference over hypotheses.\nFor example, consider what happens when \n and \n is highly correlated with", ", meaning that the data look like a line, as shown in the left panel of the figure\nbelow. Thus, there isn\u2019t a unique best hyperplane. Such correlations happen often in", "real-life data, because of underlying common causes; for example, across a\npopulation, the height of people may depend on both age and amount of food\n\u03b8\u2217\naug = ([\n] [\n])\n\u22121\n[\n]Y\n= [\n]\n\u22121\n[\n]Y\n= [\n]\n\u22121", "]\n\u22121\n[\n]Y\n= [\n]\n\u22121\n[\n]Y\n= [\n]\n\u22121\n[\n]Y\n= [\n]\n= [\n]\n= [\n]\nXT\n\ud835\udfd9T\nX\n\ud835\udfd9\nXT\n\ud835\udfd9T\nXTX\nXT\ud835\udfd9\n\ud835\udfd9TX\n\ud835\udfd9T\ud835\udfd9\nXT\n\ud835\udfd9T\nXTX\nXT\ud835\udfd9\n\ud835\udfd9TX\n\ud835\udfd9T\ud835\udfd9\nXT\n\ud835\udfd9T\nXTX\n0\n0\nn\nXT\n\ud835\udfd9T\n(XTX)\u22121XTY\nn\ud835\udfd9TY\n(XTX)\u22121XTY\n0\n\u03b8\u2217\n\u03b8\u2217\n0\n\u03b80", "0\n\u03b8\u2217\n\u03b8\u2217\n0\n\u03b80\n2.7.1 Regularization and linear regression\n\u03bb\nd = 2,\nx2\nx1\n intake in the same way. This is especially the case when there are many feature", "dimensions used in the regression. Mathematically, this leads to \n close to\nsingularity, such that \n is undefined or has huge values, resulting in", "unstable models (see the middle panel of figure and note the range of the  values\u2014\nthe slope is huge!):\nA common strategy for specifying a regularizer is to use the form", "when we have some idea in advance that \n ought to be near some value \n.\nHere, the notion of distance is quantified by squaring the  norm of the parameter\nvector: for any -dimensional vector", "the  norm of  is defined as,\nIn the absence of such knowledge a default is to regularize toward zero:\nWhen this is done in the example depicted above, the regression model becomes", "stable, producing the result shown in the right-hand panel in the figure. Now the\nslope is much more sensible.\nThere are some kinds of trouble we can get into in regression problems. What if", "is not invertible?\nAnother kind of problem is overfitting: we have formulated an objective that is just\nabout fitting the data as well as possible, but we might also want to regularize to", "keep the hypothesis from getting too attached to the data.\nWe address both the problem of not being able to invert \n and the problem", "and the problem\nof overfitting using a mechanism called ridge regression. We add a regularization\nterm \n to the OLS objective, with a non-negative scalar value  to control the\nXTX\n(XTX)\u22121\ny", "XTX\n(XTX)\u22121\ny\nR(\u0398) = \u2225\u0398 \u2212\u0398prior\u22252\n\u0398\n\u0398prior\nl2\nd\nv \u2208Rd,\nl2\nv\n\u2225v\u2225=\nd\n\u2211\ni=1\n|vi|2 .\n\ue001\n\ue000\n\u23b7\nR(\u0398) = \u2225\u0398\u22252 .\n2.7.2 Ridge regression\n(XTX)\n(XTX)\u22121\n\u2225\u03b8\u22252\n\u03bb", "(XTX)\u22121\n\u2225\u03b8\u22252\n\u03bb\n tradeoff between the training error and the regularization term. Here is the ridge\nregression objective function:\nLarger  values (in magnitude) pressure  values to be near zero.", "Note that, when data isn\u2019t centered, we don\u2019t penalize \n; intuitively, \n is what\n\u201cfloats\u201d the regression surface to the right level for the data you have, and so we", "shouldn\u2019t make it harder to fit a data set where the  values tend to be around one\nmillion than one where they tend to be around one. The other parameters control", "the orientation of the regression surface, and we prefer it to have a not-too-crazy\norientation.\nThere is an analytical expression for the \n values that minimize \n, even when", ", even when\nthe data isn\u2019t centered, but it\u2019s a more complicated to derive than the solution for\nOLS, even though the process is conceptually similar: taking the gradient, setting it", "to zero, and solving for the parameters.\nThe good news is, when the dataset is centered, we again have very clean set up and\nderivation. In particular, the objective can be written as:", "and the solution is:\nOne other great news is that in Equation 2.13, the matrix we are trying to invert can\nalways be inverted! Why is the term \n invertible? Explaining this", "requires some linear algebra. The matrix \n is positive semidefinite, which\nimplies that its eigenvalues \n are greater than or equal to 0. The matrix\n has eigenvalues", "has eigenvalues \n which are guaranteed to be strictly\npositive since \n. Recalling that the determinant of a matrix is simply the\nproduct of its eigenvalues, we get that \n and conclude that", "and conclude that\n is invertible.\n2.8 Evaluating learning algorithms\nJridge(\u03b8, \u03b80) = 1\nn\nn\n\u2211\ni=1\n(\u03b8Tx(i) + \u03b80 \u2212y(i))\n2\n+ \u03bb\u2225\u03b8\u22252\n(2.10)\n\u03bb\n\u03b8\n\u03b80\n\u03b80\ny\n\u03b8, \u03b80\nJridge\nJridge(\u03b8) = 1\nn\nn\n\u2211\ni=1\n(\u03b8Tx(i) \u2212y(i))", "i=1\n(\u03b8Tx(i) \u2212y(i))\n2\n+ \u03bb\u2225\u03b8\u22252\n(2.11)\n\u03b8ridge = (XTX + n\u03bbI)\n\u22121XTY\n(2.12)\nDerivation of the Ridge Regression Solution for Centered Data Set\n(XTX + n\u03bbI)\nXTX\n{\u03b3i}i\nXTX + n\u03bbI\n{\u03b3i + n\u03bb}i\n\u03bb > 0", "{\u03b3i + n\u03bb}i\n\u03bb > 0\ndet(XTX + n\u03bbI) > 0\nXTX + n\u03bbI\nCompare Equation 2.10 and\nEquation 2.11. What is the\ndifference between the two? How\nis it possible to drop the offset\nhere?", "here?\n In this section, we will explore how to evaluate supervised machine-learning\nalgorithms. We will study the special case of applying them to regression problems,", "but the basic ideas of validation, hyper-parameter selection, and cross-validation\napply much more broadly.\nWe have seen how linear regression is a well-formed optimization problem, which", "has an analytical solution when ridge regularization is applied. But how can one\nchoose the best amount of regularization, as parameterized by ? Two key ideas", "involve the evaluation of the performance of a hypothesis, and a separate\nevaluation of the algorithm used to produce hypotheses, as described below.", "The performance of a given hypothesis  may be evaluated by measuring test error\non data that was not used to train it. Given a training set \n a regression", "a regression\nhypothesis , and if we choose squared loss, we can define the OLS training error of\n to be the mean square error between its predictions and the expected outputs:", "Test error captures the performance of  on unseen data, and is the mean square\nerror on the test set, with a nearly identical expression as that above, differing only\nin the range of index :\non", "on \n new examples that were not used in the process of constructing .\nIn machine learning in general, not just regression, it is useful to distinguish two\nways in which a hypothesis", "might contribute to test error. Two are:\nStructural error: This is error that arises because there is no hypothesis \n that", "that\nwill perform well on the data, for example because the data was really generated by\na sine wave but we are trying to fit it with a line.", "Estimation error: This is error that arises because we do not have enough data (or\nthe data are in some way unhelpful) to allow us to choose a good \n, or because", ", or because\nwe didn\u2019t solve the optimization problem well enough to find the best  given the\ndata that we had.\nWhen we increase , we tend to increase structural error but decrease estimation", "error, and vice versa.\nNote that this section is relevant to learning algorithms generally\u2014we are just introducing\nthe topic here since we now have an algorithm that can be evaluated!\n\u03bb", "\u03bb\n2.8.1 Evaluating hypotheses\nh\nDn,\nh\nh\nEtrain(h) = 1\nn\nn\n\u2211\ni=1\n[h(x(i)) \u2212y(i)]\n2\n.\nh\ni\nEtest(h) = 1\nn\u2032\nn+n\u2032\n\u2211\ni=n+1\n[h(x(i)) \u2212y(i)]\n2\nn\u2032\nh\nh \u2208H\nh \u2208H\nh \u2208H\nh\n\u03bb\n2.8.2 Evaluating learning algorithms", "A learning algorithm is a procedure that takes a data set \n as input and returns an\nhypothesis  from a hypothesis class \n; it looks like", "; it looks like\nKeep in mind that  has parameters. The learning algorithm itself may have its own\nparameters, and such parameters are often called hyperparameters. The analytical", "solutions presented above for linear regression, e.g., Equation 2.12, may be thought\nof as learning algorithms, where  is a hyperparameter that governs how the", "learning algorithm works and can strongly affect its performance.\nHow should we evaluate the performance of a learning algorithm? This can be", "tricky. There are many potential sources of variability in the possible result of\ncomputing test error on a learned hypothesis :\nWhich particular training examples occurred in", "Which particular testing examples occurred in \nRandomization inside the learning algorithm itself\nGenerally, to evaluate how well a learning algorithm works, given an unlimited data", "source, we would like to execute the following process multiple times:\nTrain on a new training set (subset of our big data source)", "Evaluate resulting  on a validation set that does not overlap the training set\n(but is still a subset of our same big data source)", "Running the algorithm multiple times controls for possible poor choices of training\nset or unfortunate randomization inside the algorithm itself.", "One concern is that we might need a lot of data to do this, and in many applications\ndata is expensive or difficult to acquire. We can re-use data with cross validation (but", "it\u2019s harder to do theoretical analysis).\nAlgorithm 2.1 Cross-Validate\nRequire: Data , integer \nDivide  into  chunks \n (of roughly equal size)\nfor \n to  do\nTrain \n on \n (withholding chunk", "as the validation set)\nCompute \"test\" error \n on withheld data \nend for\nreturn \nIt\u2019s very important to understand that (cross-)validation neither delivers nor", "evaluates a single particular hypothesis . It evaluates the learning algorithm that\nproduces hypotheses.\nDn\nh\nH\nDtrain \u27f6\n\u27f6h\nlearning alg (H)\nh\n\u03bb\nh\nDtrain\nDtest\n2.8.2.1 Validation\nh", "h\n2.8.2.2 Cross validation\nD\nk\n1:\nD\nk\nD1, D2, \u2026 , Dk\n2:\ni = 1\nk\n3:\nhi\nD \u2216Di\nDi\n4:\nEi(hi)\nDi\n5:\n6:\n1\nk \u2211k\ni=1 Ei(hi)\nh\n The hyper-parameters of a learning algorithm affect how the algorithm works but", "they are not part of the resulting hypothesis. So, for example,  in ridge regression\naffects which hypothesis will be returned, but  itself doesn\u2019t show up in the", "hypothesis (the hypothesis is specified using parameters  and \n).\nYou can think about each different setting of a hyper-parameter as specifying a\ndifferent learning algorithm.", "In order to pick a good value of the hyper-parameter, we often end up just trying a\nlot of values and seeing which one works best via validation or cross-validation.\n\u2753 Study Question", "\u2753 Study Question\nHow could you use cross-validation to decide whether to use analytic ridge\nregression or our random-regression algorithm and to pick  for random\nregression or  for ridge regression?", "2.8.2.3 Hyperparameter tuning\n\u03bb\n\u03bb\n\u03b8\n\u03b80\nk\n\u03bb"]